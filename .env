# Universal AI Tools Environment Configuration

# Server Configuration
NODE_ENV=development
PORT=9999
HOST=localhost

# Supabase Configuration (from running instance)
SUPABASE_URL=http://127.0.0.1:54321
SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0
SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU
DATABASE_URL=postgresql://postgres:postgres@127.0.0.1:54322/postgres

# Redis Configuration
REDIS_URL=redis://localhost:6379

# Security Configuration
JWT_SECRET=super-secret-jwt-token-with-at-least-32-characters-long
ENCRYPTION_KEY=your-encryption-key-here-minimum-32-characters-1234567890
API_KEY_SALT=your-api-key-salt-here

# Memory Optimization Configuration
LFM2_MAX_PENDING=15
LFM2_MAX_CONCURRENCY=1
LFM2_MAX_TOKENS=256
LFM2_TIMEOUT_MS=6000
DISABLE_LFM2=false
MEMORY_AGGRESSIVE_CLEANUP=true

# LLM Configuration
OLLAMA_URL=http://localhost:11434
LM_STUDIO_URL=http://localhost:5901
OPENAI_API_KEY=your-openai-api-key-here
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Logging
LOG_LEVEL=info

# Development
DEVELOPMENT_MOCK_API_KEY=dev-mock-key-for-testing

# Advanced AI Features
ENABLE_ALPHA_EVOLVE=true
ENABLE_AUTO_ARCHITECTURE=true
ENABLE_SELF_MODIFYING=true
ENABLE_HOT_RELOAD=true
ENABLE_INTELLIGENT_FIXES=true
ENABLE_TOOL_MAKER=true

# Agent Zero Style Features
ENABLE_ORGANIC_GROWTH=true
ENABLE_DYNAMIC_AGENTS=true
ENABLE_AGENT_SPAWNING=true
ENABLE_TOOL_CREATION=true
ENABLE_SCHEMA_EVOLUTION=true

# AI Learning Configuration
AI_MEMORY_ENABLED=true
AI_LEARNING_MODE=continuous
AI_EVOLUTION_RATE=aggressive
AI_CONFIDENCE_THRESHOLD=0.85
AGENT_AUTONOMY_LEVEL=0.8
CREATIVITY_THRESHOLD=0.7
CURIOSITY_LEVEL=0.9

# Performance Optimization
ENABLE_SMART_CACHING=true
ENABLE_PREDICTIVE_LOADING=true
ENABLE_AUTO_OPTIMIZATION=true

# Developer Experience
ENABLE_VOICE_COMMANDS=false
ENABLE_PREDICTIVE_CODING=true
ENABLE_AUTO_DOCUMENTATION=true

# Neo4j Configuration for GraphRAG R1
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password123

# Autonomous Actions
ENABLE_AUTONOMOUS_ACTIONS=true
MAX_AUTONOMOUS_ACTIONS_PER_HOUR=10
MAX_CONCURRENT_AUTONOMOUS_ACTIONS=3
LOW_RISK_MIN_CONFIDENCE=0.85
MEDIUM_RISK_MIN_CONFIDENCE=0.90
HIGH_RISK_MIN_CONFIDENCE=0.95
AUTO_APPROVE_MEDIUM_RISK=false
ROLLBACK_COOLDOWN_MS=1800000
SIMILAR_ACTION_COOLDOWN_MS=900000
MAX_PARAMETER_CHANGE_PERCENT=15
REQUIRE_APPROVAL_FOR=model_switch,feature_toggle

# Self-Improvement
ENABLE_CODE_EVOLUTION=true
ENABLE_PATTERN_LEARNING=true
ENABLE_AUTOMATIC_REFACTORING=true

# MLX Configuration
MLX_PYTHON_PATH=/Users/christianmerrill/miniforge3/bin/python
MLX_MODELS_PATH=/Users/christianmerrill/Desktop/universal-ai-tools/models
ENABLE_MLX_FINE_TUNING=true

# Telemetry Configuration
ENABLE_TRACING=true
ENABLE_METRICS=true
ENABLE_TELEMETRY_LOGGING=true
TRACE_SAMPLING_RATE=1.0
ENABLE_CONSOLE_EXPORT=true
ENABLE_JAEGER_EXPORT=true
ENABLE_ZIPKIN_EXPORT=false
ENABLE_OTLP_EXPORT=false
ENABLE_PROMETHEUS_EXPORT=false
ENABLE_HEAVY_SERVICES=false
USE_MOCK_LFM2=true
LAZY_LOAD_SERVICES=true
