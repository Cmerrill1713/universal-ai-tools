#!/usr/bin/env node
/**
 * Multi-Provider Parallel LLM Test
 * Tests parallel processing across Ollama and MLX providers
 */

async function testMultiProviderParallel() {
  console.log('üåê MULTI-PROVIDER PARALLEL LLM TESTING');
  console.log('');
  
  const testMessage = { role: 'user', content: 'What is the capital of Mars?' };
  
  console.log('=== STEP 1: PROVIDER HEALTH CHECK ===');
  
  // Check Ollama health
  try {
    const ollamaHealth = await fetch('http://localhost:11434/api/tags');
    const ollamaData = await ollamaHealth.json();
    console.log('‚úÖ Ollama Provider:');
    console.log(`   Status: Healthy`);
    console.log(`   Models: ${ollamaData.models?.length || 0} available`);
  } catch (error) {
    console.log('‚ùå Ollama Provider: Unavailable');
  }
  
  // Check MLX health
  try {
    const mlxHealth = await fetch('http://localhost:8001/health');
    const mlxData = await mlxHealth.json();
    console.log('‚úÖ MLX Provider:');
    console.log(`   Status: ${mlxData.status}`);
    console.log(`   Models: ${mlxData.models_loaded || 0} loaded`);
  } catch (error) {
    console.log('‚ùå MLX Provider: Unavailable');
  }
  
  console.log('');

  console.log('=== STEP 2: SEQUENTIAL MULTI-PROVIDER TEST ===');
  const sequentialStart = Date.now();
  
  // Test Ollama
  const ollamaStart = Date.now();
  let ollamaResult = null;
  try {
    const ollamaResponse = await fetch('http://localhost:11434/api/chat', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: 'gpt-oss:20b',
        messages: [testMessage],
        stream: false
      })
    });
    
    const ollamaData = await ollamaResponse.json();
    ollamaResult = {
      provider: 'Ollama',
      model: 'gpt-oss:20b',
      response: ollamaData.message?.content || '',
      responseTime: Date.now() - ollamaStart,
      success: true
    };
    console.log(`   Ollama: ${ollamaResult.responseTime}ms`);
  } catch (error) {
    ollamaResult = {
      provider: 'Ollama',
      model: 'gpt-oss:20b',
      response: '',
      responseTime: Date.now() - ollamaStart,
      success: false,
      error: error.message
    };
    console.log(`   Ollama: FAILED`);
  }
  
  // Test MLX
  const mlxStart = Date.now();
  let mlxResult = null;
  try {
    const mlxResponse = await fetch('http://localhost:8001/v1/chat/completions', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: 'mlx-qwen2.5-0.5b',
        messages: [testMessage],
        max_tokens: 50
      })
    });
    
    const mlxData = await mlxResponse.json();
    mlxResult = {
      provider: 'MLX',
      model: 'mlx-qwen2.5-0.5b',
      response: mlxData.choices[0].message.content,
      responseTime: Date.now() - mlxStart,
      success: true
    };
    console.log(`   MLX: ${mlxResult.responseTime}ms`);
  } catch (error) {
    mlxResult = {
      provider: 'MLX',
      model: 'mlx-qwen2.5-0.5b',
      response: '',
      responseTime: Date.now() - mlxStart,
      success: false,
      error: error.message
    };
    console.log(`   MLX: FAILED`);
  }
  
  const sequentialTotal = Date.now() - sequentialStart;
  console.log(`   Total Sequential Time: ${sequentialTotal}ms`);
  console.log('');

  console.log('=== STEP 3: PARALLEL MULTI-PROVIDER TEST ===');
  const parallelStart = Date.now();
  
  const parallelPromises = [
    // Ollama promise
    (async () => {
      const start = Date.now();
      try {
        const response = await fetch('http://localhost:11434/api/chat', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            model: 'gpt-oss:20b',
            messages: [testMessage],
            stream: false
          })
        });
        
        const data = await response.json();
        return {
          provider: 'Ollama',
          model: 'gpt-oss:20b',
          response: data.message?.content || '',
          responseTime: Date.now() - start,
          success: true
        };
      } catch (error) {
        return {
          provider: 'Ollama',
          model: 'gpt-oss:20b',
          response: '',
          responseTime: Date.now() - start,
          success: false,
          error: error.message
        };
      }
    })(),
    
    // MLX promise
    (async () => {
      const start = Date.now();
      try {
        const response = await fetch('http://localhost:8001/v1/chat/completions', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            model: 'mlx-qwen2.5-0.5b',
            messages: [testMessage],
            max_tokens: 50
          })
        });
        
        const data = await response.json();
        return {
          provider: 'MLX',
          model: 'mlx-qwen2.5-0.5b',
          response: data.choices[0].message.content,
          responseTime: Date.now() - start,
          success: true
        };
      } catch (error) {
        return {
          provider: 'MLX',
          model: 'mlx-qwen2.5-0.5b',
          response: '',
          responseTime: Date.now() - start,
          success: false,
          error: error.message
        };
      }
    })()
  ];
  
  const parallelResults = await Promise.all(parallelPromises);
  const parallelTotal = Date.now() - parallelStart;
  
  parallelResults.forEach(result => {
    console.log(`   ${result.provider}: ${result.responseTime}ms`);
  });
  console.log(`   Total Parallel Time: ${parallelTotal}ms`);
  console.log('');

  console.log('=== STEP 4: PERFORMANCE COMPARISON ===');
  const speedImprovement = ((sequentialTotal - parallelTotal) / sequentialTotal * 100).toFixed(1);
  console.log(`üìà Multi-Provider Performance Results:`);
  console.log(`   Sequential: ${sequentialTotal}ms`);
  console.log(`   Parallel: ${parallelTotal}ms`);
  console.log(`   Speed Improvement: ${speedImprovement}%`);
  console.log(`   Time Saved: ${sequentialTotal - parallelTotal}ms`);
  console.log('');

  console.log('=== STEP 5: RESPONSE COMPARISON ===');
  console.log('üìù Multi-Provider Response Quality:');
  parallelResults.forEach((result, index) => {
    console.log(`   ${result.provider} (${result.model}):`);
    console.log(`     Response: "${result.response.substring(0, 60)}..."`);
    console.log(`     Time: ${result.responseTime}ms`);
    console.log(`     Success: ${result.success ? '‚úÖ' : '‚ùå'}`);
    if (!result.success) {
      console.log(`     Error: ${result.error}`);
    }
  });
  console.log('');

  console.log('=== STEP 6: BEST RESPONSE SELECTION ===');
  const bestResponse = parallelResults
    .filter(r => r.success)
    .sort((a, b) => a.responseTime - b.responseTime)[0];
  
  if (bestResponse) {
    console.log('üèÜ Best Response:');
    console.log(`   Provider: ${bestResponse.provider}`);
    console.log(`   Model: ${bestResponse.model}`);
    console.log(`   Response Time: ${bestResponse.responseTime}ms`);
    console.log(`   Content: "${bestResponse.response}"`);
  } else {
    console.log('‚ùå No successful responses received');
  }
  console.log('');

  console.log('=== STEP 7: PROVIDER RELIABILITY ===');
  const successfulProviders = parallelResults.filter(r => r.success).length;
  const totalProviders = parallelResults.length;
  const reliability = (successfulProviders / totalProviders * 100).toFixed(1);
  
  console.log('üõ°Ô∏è Provider Reliability:');
  console.log(`   Successful Providers: ${successfulProviders}/${totalProviders}`);
  console.log(`   Reliability Rate: ${reliability}%`);
  console.log(`   Redundancy Benefit: ${totalProviders > 1 ? '‚úÖ' : '‚ùå'}`);
  console.log('');

  console.log('üéØ MULTI-PROVIDER PARALLEL TEST COMPLETE!');
  console.log('');
  console.log('‚úÖ BENEFITS DEMONSTRATED:');
  console.log(`   ‚Ä¢ ${speedImprovement}% faster response times`);
  console.log(`   ‚Ä¢ ${reliability}% provider reliability`);
  console.log('   ‚Ä¢ Cross-provider redundancy');
  console.log('   ‚Ä¢ Automatic best response selection');
  console.log('   ‚Ä¢ Improved fault tolerance');
  console.log('   ‚Ä¢ Better resource utilization');
  console.log('');
  console.log('üöÄ MULTI-PROVIDER PARALLEL LLM PROCESSING IS WORKING!');
}

// Run the test
testMultiProviderParallel();
