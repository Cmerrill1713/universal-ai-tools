services:
  # Redis for caching
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # API Gateway - Main entry point
  api-gateway:
    build:
      context: .
      dockerfile: go-services/api-gateway/Dockerfile
    ports:
      - "8080:8080"
    depends_on:
      redis:
        condition: service_healthy
    environment:
      - PORT=8080
      - REDIS_ADDR=redis:6379
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - universal-ai-network

  # Cache Coordinator
  cache-coordinator:
    build:
      context: ..
      dockerfile: go-services/cache-coordinator/Dockerfile
    ports:
      - "8012:8012"
    depends_on:
      redis:
        condition: service_healthy
    environment:
      - PORT=8012
      - REDIS_ADDR=redis:6379
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8012/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - universal-ai-network

  # Load Balancer
  load-balancer:
    build:
      context: ..
      dockerfile: go-services/load-balancer/Dockerfile
    ports:
      - "8011:8011"
    environment:
      - PORT=8011
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8011/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - universal-ai-network

  # Metrics Aggregator
  metrics-aggregator:
    build:
      context: ..
      dockerfile: go-services/metrics-aggregator/Dockerfile
    ports:
      - "8013:8013"
    environment:
      - PORT=8013
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8013/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - universal-ai-network

  # Chat Service
  chat-service:
    build:
      context: ..
      dockerfile: go-services/chat-service/Dockerfile
    ports:
      - "8016:8016"
    depends_on:
      redis:
        condition: service_healthy
    environment:
      - PORT=8016
      - REDIS_ADDR=redis:6379
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8016/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - universal-ai-network

  # Memory Service
  memory-service:
    build:
      context: ..
      dockerfile: go-services/memory-service/Dockerfile
    ports:
      - "8017:8017"
    depends_on:
      redis:
        condition: service_healthy
    environment:
      - PORT=8017
      - REDIS_ADDR=redis:6379
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8017/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - universal-ai-network

  # WebSocket Hub
  websocket-hub:
    build:
      context: ..
      dockerfile: go-services/websocket-hub/Dockerfile
    ports:
      - "8018:8018"
    environment:
      - PORT=8018
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8018/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - universal-ai-network

  # Auth Service
  auth-service:
    build:
      context: ..
      dockerfile: go-services/auth-service/Dockerfile
    ports:
      - "8015:8015"
    depends_on:
      redis:
        condition: service_healthy
    environment:
      - PORT=8015
      - REDIS_ADDR=redis:6379
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8015/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - universal-ai-network

  # Legacy Bridge
  legacy-bridge:
    build:
      context: ..
      dockerfile: nodejs-api-server/Dockerfile
    ports:
      - "9999:9999"
    environment:
      - PORT=9999
      - NODE_ENV=production
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9999/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - universal-ai-network

volumes:
  redis_data:

networks:
  universal-ai-network:
    driver: bridge
