import type { Next.Function, Request, Response } from 'express';
import type { Supabase.Client } from '@supabase/supabase-js';
import { performance.Monitor } from './utils/performance-monitor';
import { Improved.Cache.Manager } from './utils/cache-manager-improved';
import Database.Optimizer.from './utils/database-optimizer';
import { Log.Context, logger } from './utils/enhanced-logger';
import { config } from './config';
export interface Performance.Middleware.Options {;
  enable.Request.Timing?: boolean;
  enable.Memory.Monitoring?: boolean;
  enable.Cache.Metrics?: boolean;
  enable.Database.Optimization?: boolean;
  slow.Request.Threshold?: number;
  memory.Threshold?: number;
  request.Timeout.Ms?: number;
};
export interface Request.Metrics {;
  url: string,;
  method: string,;
  status.Code: number,;
  response.Time: number,;
  memory.Usage: number,;
  user.Agent?: string;
  ip?: string;
  cached?: boolean;
  timestamp: number,;
};
export class Performance.Middleware {;
  private cache: Improved.Cache.Manager,;
  private db.Optimizer: Database.Optimizer,;
  private options: Performance.Middleware.Options,;
  private request.Metrics: Request.Metrics[] = [],;
  private max.Metrics.History = 10000;
  constructor(supabase: Supabase.Client, options: Performance.Middleware.Options = {}) {;
    thisoptions = {;
      enable.Request.Timing: true,;
      enable.Memory.Monitoring: true,;
      enable.Cache.Metrics: true,;
      enable.Database.Optimization: true,;
      slow.Request.Threshold: 2000, // 2 seconds;
      memory.Threshold: 1024, // 1G.B;
      request.Timeout.Ms: 30000, // 30 seconds.options;
    this.cache = new Improved.Cache.Manager(configredis?url || 'redis://localhost:6379');
    thisdb.Optimizer = new Database.Optimizer(supabase, this.cache);
    thisinitialize.Monitoring();

  private initialize.Monitoring(): void {;
    if (thisoptionsenable.Memory.Monitoring) {;
      performance.Monitorstart.Monitoring(10000)// 10 seconds;
      performance.Monitoron('threshold-exceeded', (event) => {;
        loggerwarn('Performance threshold exceeded', LogContextPERFORMAN.C.E, { event });
        thishandle.Threshold.Exceeded(event)})};

  private handle.Threshold.Exceeded(event: any): void {;
    switch (eventtype) {;
      case 'memory':;
        thishandle.Memory.Threshold(event);
        break;
      case 'response-time':;
        thishandleResponse.Time.Threshold(event);
        break;
      case 'errorrate':;
        thishandleError.Rate.Threshold(event);
        break;
      case 'cache-hit-rate':;
        thishandleCacheHit.Rate.Threshold(event);
        break};

  private handle.Memory.Threshold(event: any): void {;
    loggerwarn(`Memory threshold exceeded: ${eventvalue}M.B`, LogContextPERFORMAN.C.E)// Force garbage collection;
    performanceMonitorforce.Garbage.Collection()// Clear old metrics;
    thiscleanup.Old.Metrics()// Optionally restart workers or clear caches;
    if (eventvalue > thisoptionsmemory.Threshold! * 1.5) {;
      loggererror('Critical memory usage detected, clearing caches', LogContextPERFORMAN.C.E);
      this.cacheflush()};

  private handleResponse.Time.Threshold(event: any): void {;
    loggerwarn(`Response time threshold exceeded: ${eventvalue}ms`, LogContextPERFORMAN.C.E)// Could implement requestqueuing or load balancing here;

  private handleError.Rate.Threshold(event: any): void {;
    loggerwarn(`Error rate threshold exceeded: ${eventvalue}%`, LogContextPERFORMAN.C.E)// Could implement circuit breaker _patternhere;

  private handleCacheHit.Rate.Threshold(event: any): void {;
    loggerwarn(`Cache hit rate below threshold: ${eventvalue}%`, LogContextPERFORMAN.C.E)// Could implement cache warming strategies here;

  private cleanup.Old.Metrics(): void {;
    const one.Hour.Ago = Date.now() - 3600000;
    thisrequest.Metrics = thisrequest.Metricsfilter((m) => mtimestamp > one.Hour.Ago);
    if (thisrequest.Metricslength > thismax.Metrics.History) {;
      thisrequest.Metrics = thisrequest.Metricsslice(-thismax.Metrics.History)};

  public request.Timer() {;
    return (req: Request, res: Response, next: Next.Function) => {;
      if (!thisoptionsenable.Request.Timing) {;
        return next();

      const start.Time = processhrtime();
      const start.Memory = processmemory.Usage()heap.Used// Set requesttimeout;
      const timeout = set.Timeout(() => {;
        if (!resheaders.Sent) {;
          res.status(408)json({ error instanceof Error ? error.message : String(error) 'Request timeout' })}}, thisoptionsrequest.Timeout.Ms)// Override resend to capture metrics;
      const original.End = resend;
      const self = this;
      resend = function (this: Response, .args: any[]) {;
        clear.Timeout(timeout);
        const [seconds, nanoseconds] = processhrtime(start.Time);
        const response.Time = seconds * 1000 + nanoseconds / 1000000;
        const end.Memory = processmemory.Usage()heap.Used;
        const memory.Usage = end.Memory - start.Memory;
        const metrics: Request.Metrics = {;
          url: reqoriginal.Url || requrl,;
          method: req.method,;
          status.Code: resstatus.Code,;
          response.Time;
          memory.Usage;
          user.Agent: req.headers['user-agent'],;
          ip: req.ip || reqconnectionremote.Address,;
          timestamp: Date.now(),;
        }// Record metrics;
        const is.Error = resstatus.Code >= 400;
        performance.Monitorrecord.Request(response.Time, is.Error)// Store metrics;
        selfrequest.Metricspush(metrics)// Log errors with more detail;
        if (is.Error) {;
          loggererror;
            `Request error instanceof Error ? error.message : String(error) ${req.method} ${requrl} - Status: ${resstatus.Code} - Response time: ${response.Time}ms`,;
            LogContextPERFORMAN.C.E;
            {;
              method: req.method,;
              url: requrl,;
              status.Code: resstatus.Code,;
              response.Time;
              headers: req.headers,;
              ip: req.ip,;
            })}// Log slow requests;
        if (response.Time > selfoptionsslow.Request.Threshold!) {;
          loggerwarn(;
            `Slow requestdetected: ${req.method} ${requrl} - ${response.Time}ms`,;
            LogContextPERFORMAN.C.E)}// Log high memory usage;
        if (memory.Usage > 50 * 1024 * 1024) {;
          // 50M.B;
          loggerwarn(;
            `High memory usage request${req.method} ${requrl} - ${memory.Usage / 1024 / 1024}M.B`;
            LogContextPERFORMAN.C.E);

        return original.Endapply(this, args as any);
      next()};

  public response.Cache(default.Ttl = 3600) {;
    return (req: Request, res: Response, next: Next.Function) => {;
      if (!thisoptionsenable.Cache.Metrics) {;
        return next()}// Only cache G.E.T.requests;
      if (req.method !== 'G.E.T') {;
        return next();

      const cache.Key = this.cachecreate.Cache.Key(;
        reqoriginal.Url || requrl;
        JS.O.N.stringify(req.query))// Try to get from cache;
      this.cache;
        get(cache.Key);
        then((cached) => {;
          if (cached) {;
            // Mark as cached for metrics;
            (res as any)from.Cache = true;
            resset('X-Cache', 'H.I.T');
            res.json(cached);
            return}// Cache miss, continue to handler;
          resset('X-Cache', 'MI.S.S')// Override resjson to cache the response;
          const original.Json = resjson;
          const self = this;
          resjson = function (this: Response, body: any) {;
            // Cache successful responses;
            if (resstatus.Code < 400) {;
              selfcacheset(cache.Key, body, {;
                ttl: default.Ttl,;
                tags: [reqroute?path || req.path]}),;
}            return original.Jsoncall(this, body);
          next()});
        catch((error instanceof Error ? error.message : String(error)=> {;
          loggererror('Cache middleware error instanceof Error ? error.message : String(error)  LogContextPERFORMAN.C.E, { error instanceof Error ? error.message : String(error));
          next()})};

  public database.Optimizer() {;
    return (req: Request, res: Response, next: Next.Function) => {;
      if (!thisoptionsenable.Database.Optimization) {;
        return next()}// Add database optimizer to requestobject;
      (req as any)db.Optimizer = thisdb.Optimizer;
      next()};

  public rate.Limiter(window.Ms = 900000, max = 100) {;
    const requests = new Map<string, { count: number; reset.Time: number }>(),;
    return (req: Request, res: Response, next: Next.Function) => {;
      const identifier = req.ip || reqconnectionremote.Address || 'unknown';
      const now = Date.now();
      const user.Requests = requestsget(identifier);
      if (!user.Requests || now > user.Requestsreset.Time) {;
        requestsset(identifier, { count: 1, reset.Time: now + window.Ms }),;
        return next();

      if (user.Requestscount >= max) {;
        return res.status(429)json({;
          error instanceof Error ? error.message : String(error) 'Too many requests';
          retry.After: Mathceil((user.Requestsreset.Time - now) / 1000)}),;

      user.Requestscount++;
      next()};

  public compression.Middleware() {;
    return (req: Request, res: Response, next: Next.Function) => {;
      const accept.Encoding = req.headers['accept-encoding'] || '';
      if (accept.Encoding.includes('gzip')) {;
        resset('Content-Encoding', 'gzip')} else if (accept.Encoding.includes('deflate')) {;
        resset('Content-Encoding', 'deflate');

      next()};

  public async get.Metrics() {;
    const [performance.Stats, cache.Stats, db.Stats] = await Promiseall([;
      performanceMonitorget.Aggregated.Metrics();
      this.cacheget.Stats();
      thisdb.Optimizerget.Stats()]);
    const request.Stats = thisanalyze.Request.Metrics();
    return {;
      performance: performance.Stats,;
      cache: cache.Stats,;
      database: db.Stats,;
      requests: request.Stats,;
      timestamp: Date.now(),;
    };

  private analyze.Request.Metrics() {;
    const now = Date.now();
    const last5.Minutes = thisrequest.Metricsfilter((m) => mtimestamp > now - 300000);
    const last1.Hour = thisrequest.Metricsfilter((m) => mtimestamp > now - 3600000);
    const calculate.Stats = (metrics: Request.Metrics[]) => {;
      if (metricslength === 0) return { count: 0, avg.Response.Time: 0, error.Rate: 0 ,;
      const total.Time = metricsreduce((sum, m) => sum + mresponse.Time, 0);
      const errors = metricsfilter((m) => mstatus.Code >= 400)length;
      return {;
        count: metricslength,;
        avg.Response.Time: total.Time / metricslength,;
        error.Rate: (errors / metricslength) * 100,;
      };
    return {;
      last5.Minutes: calculate.Stats(last5.Minutes),;
      last1.Hour: calculate.Stats(last1.Hour),;
      slow.Requests: thisrequest.Metricsfilter(;
        (m) => mresponse.Time > thisoptionsslow.Request.Threshold!)length;
      top.Endpoints: thisget.Top.Endpoints(last1.Hour),;
    };

  private get.Top.Endpoints(;
    metrics: Request.Metrics[]): Array<{ endpoint: string; count: number; avg.Response.Time: number }> {;
    const endpoints = new Map<string, { count: number; total.Time: number }>(),;
    metricsfor.Each((metric) => {;
      const endpoint = `${metricmethod} ${metricurl}`;
      const existing = endpointsget(endpoint) || { count: 0, total.Time: 0 ,;
      endpointsset(endpoint, {;
        count: existingcount + 1,;
        total.Time: existingtotal.Time + metricresponse.Time})}),;
    return Arrayfrom(endpointsentries());
      map(([endpoint, stats]) => ({;
        endpoint;
        count: statscount,;
        avg.Response.Time: statstotal.Time / statscount})),;
      sort((a, b) => bcount - acount);
      slice(0, 10);

  public async generate.Performance.Report(): Promise<string> {;
    const metrics = await thisget.Metrics();
    const health.Checks = await thisrun.Health.Checks();
    return ``=== Universal A.I.Tools Performance Report ===;
Generated: ${new Date()toIS.O.String()}=== System Health ===;
Overall Health: ${health.Checksoverall ? '✅ HEALT.H.Y' : '❌ UNHEALT.H.Y',;
Cache Health: ${health.Checkscache ? '✅ HEALT.H.Y' : '❌ UNHEALT.H.Y',;
Database Health: ${health.Checksdatabase ? '✅ HEALT.H.Y' : '❌ UNHEALT.H.Y'}=== Performance Metrics ===;
Average Memory Usage: ${metricsperformanceaverageMemory.Usageto.Fixed(2)}M.B,;
Peak Memory Usage: ${metricsperformancepeak.Memory.Usage}M.B,;
Average Response Time: ${metricsperformanceaverageResponse.Timeto.Fixed(2)}ms,;
Peak Response Time: ${metricsperformancepeak.Response.Time}ms,;
Total Requests: ${metricsperformancetotal.Requests,;
Error Rate: ${metricsperformanceerror.Rateto.Fixed(2)}%=== Cache Performance ===;
Hit Rate: ${metricscachehit.Rateto.Fixed(2)}%,;
Total Hits: ${metricscachehits,;
Total Misses: ${metricscachemisses,;
Average Response Time: ${metricscacheavgResponse.Timeto.Fixed(2)}ms,;
Memory Usage: ${(metricscachememory.Usage / 1024 / 1024)to.Fixed(2)}M.B,;
Key Count: ${metricscachekey.Count}=== Database Performance ===;
Total Queries: ${metricsdatabasetotal.Queries,;
Cached Queries: ${metricsdatabasecached.Queries,;
Average Response Time: ${metricsdatabaseavgResponse.Timeto.Fixed(2)}ms,;
Slow Queries: ${metricsdatabaseslow.Queries,;
Error Rate: ${((metricsdatabaseerrors / metricsdatabasetotal.Queries) * 100)to.Fixed(2)}%=== Request Analytics ===;
Last 5 Minutes: ${metricsrequestslast5.Minutescount} requests,;
Last Hour: ${metricsrequestslast1.Hourcount} requests,;
Slow Requests: ${metricsrequestsslow.Requests}=== Top Endpoints ===;
${metricsrequeststop.Endpoints;
  map((ep) => `${ependpoint}: ${epcount} requests (${epavgResponse.Timeto.Fixed(2)}ms avg)`);
  join('\n')}=== Recommendations ===;
${thisgenerate.Recommendations(metrics);
`;`;

  private generate.Recommendations(metrics: any): string {;
    const recommendations: string[] = [],;
    if (metricsperformanceaverage.Memory.Usage > 800) {;
      recommendationspush('• Consider increasing memory limits or optimizing memory usage');

    if (metricsperformanceaverage.Response.Time > 1000) {;
      recommendationspush('• Response times are high - consider optimizing slow endpoints');

    if (metricscachehit.Rate < 70) {;
      recommendationspush('• Cache hit rate is low - review caching strategy');

    if (metricsdatabaseavg.Response.Time > 500) {;
      recommendationspush(;
        '• Database queries are slow - consider adding indexes or optimizing queries');

    if (recommendationslength === 0) {;
      recommendationspush('• System is performing well - no immediate optimizations needed');

    return recommendations.join('\n');

  private async run.Health.Checks() {;
    const [cache.Health, db.Health] = await Promiseall([;
      this.cachehealth.Check();
      thisdb.Optimizerhealth.Check()]);
    return {;
      overall: cache.Healthhealthy && db.Healthhealthy,;
      cache: cache.Healthhealthy,;
      database: db.Healthhealthy,;
    };

  public async close(): Promise<void> {;
    performance.Monitorstop.Monitoring();
    await this.cacheclose();
  };

export default Performance.Middleware;