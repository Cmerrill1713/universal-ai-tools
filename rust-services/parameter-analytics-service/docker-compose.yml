# Docker Compose configuration for Parameter Analytics Service
# Production-ready deployment with Redis and monitoring

version: '3.8'

services:
  parameter-analytics-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    image: universal-ai-tools/parameter-analytics-service:latest
    container_name: parameter-analytics-service
    restart: unless-stopped
    
    environment:
      - RUST_LOG=info
      - RUST_BACKTRACE=1
      - REDIS_URL=redis://redis:6379
      - NODE_ENV=production
    
    volumes:
      - ./config:/app/config:ro
      - ./logs:/app/logs
      - ./cache:/app/cache
    
    depends_on:
      - redis
      - redis-insight
    
    networks:
      - analytics-network
    
    ports:
      - "8080:8080"  # If running as standalone service
    
    healthcheck:
      test: ["CMD", "echo", "Service health check"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  redis:
    image: redis:7.2-alpine
    container_name: parameter-analytics-redis
    restart: unless-stopped
    
    command: >
      redis-server
      --appendonly yes
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --save 60 1000
    
    volumes:
      - redis-data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf:ro
    
    ports:
      - "6379:6379"
    
    networks:
      - analytics-network
    
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis-insight:
    image: redislabs/redisinsight:latest
    container_name: parameter-analytics-redis-insight
    restart: unless-stopped
    
    ports:
      - "8001:8001"
    
    environment:
      - REDIS_HOSTS=redis:redis:6379
    
    depends_on:
      - redis
    
    networks:
      - analytics-network
    
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  prometheus:
    image: prom/prometheus:latest
    container_name: parameter-analytics-prometheus
    restart: unless-stopped
    
    ports:
      - "9090:9090"
    
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    
    networks:
      - analytics-network
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  grafana:
    image: grafana/grafana:latest
    container_name: parameter-analytics-grafana
    restart: unless-stopped
    
    ports:
      - "3000:3000"
    
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
    
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    
    depends_on:
      - prometheus
    
    networks:
      - analytics-network
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  analytics-network:
    driver: bridge
    name: parameter-analytics-network

volumes:
  redis-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local