-- Register LLM models as Supabase users for clean tracking and permissions

-- Function to register an LLM model as a user
CREATE OR REPLACE FUNCTION register_llm_model(
    p_model_name TEXT,
    p_provider TEXT,
    p_capabilities JSONB DEFAULT '{}',
    p_rate_limits JSONB DEFAULT '{"requests_per_minute": 60, "tokens_per_minute": 40000}'
) RETURNS UUID AS $$
DECLARE
    v_user_id UUID;
    v_model_id UUID;
    v_email TEXT;
    v_api_key_id UUID;
BEGIN
    -- Generate unique email for the model
    v_email := LOWER(REPLACE(p_model_name, ' ', '_')) || '@llm.universal-ai-tools.local';
    
    -- Check if user already exists
    SELECT id INTO v_user_id 
    FROM auth.users 
    WHERE email = v_email;
    
    IF v_user_id IS NULL THEN
        -- Create new auth user for the model
        -- Note: In production, this would use Supabase Admin API
        -- For now, we'll create a placeholder record
        v_user_id := gen_random_uuid();
        
        -- Insert into auth.users (requires service role)
        -- This is a simplified version - actual implementation would use Supabase Admin SDK
        INSERT INTO auth.users (
            id,
            email,
            encrypted_password,
            email_confirmed_at,
            created_at,
            updated_at,
            raw_app_meta_data,
            raw_user_meta_data
        ) VALUES (
            v_user_id,
            v_email,
            crypt('llm-model-user', gen_salt('bf')),
            NOW(),
            NOW(),
            NOW(),
            jsonb_build_object('provider', 'email', 'providers', ARRAY['email']),
            jsonb_build_object(
                'is_llm', true,
                'model_name', p_model_name,
                'provider', p_provider
            )
        );
    END IF;
    
    -- Check if model already exists
    SELECT id INTO v_model_id
    FROM llm_users.models
    WHERE model_name = p_model_name;
    
    IF v_model_id IS NOT NULL THEN
        -- Update existing model
        UPDATE llm_users.models
        SET provider = p_provider,
            capabilities = p_capabilities,
            rate_limits = p_rate_limits,
            updated_at = NOW()
        WHERE id = v_model_id;
    ELSE
        -- Get or create API key reference
        SELECT id INTO v_api_key_id
        FROM vault.llm_secrets
        WHERE name = p_provider || '_api_key';
        
        -- Create new model record
        INSERT INTO llm_users.models (
            model_name,
            provider,
            user_id,
            api_key_id,
            capabilities,
            rate_limits
        ) VALUES (
            p_model_name,
            p_provider,
            v_user_id,
            v_api_key_id,
            p_capabilities,
            p_rate_limits
        ) RETURNING id INTO v_model_id;
    END IF;
    
    -- Create API key for the model user
    PERFORM create_model_api_key(v_model_id);
    
    RETURN v_model_id;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Function to create API key for model
CREATE OR REPLACE FUNCTION create_model_api_key(p_model_id UUID)
RETURNS TEXT AS $$
DECLARE
    v_api_key TEXT;
    v_key_name TEXT;
BEGIN
    -- Generate API key
    v_api_key := 'uai_' || encode(gen_random_bytes(32), 'base64');
    v_api_key := REPLACE(v_api_key, '/', '_');
    v_api_key := REPLACE(v_api_key, '+', '-');
    
    -- Get model name for key naming
    SELECT 'model_key_' || LOWER(REPLACE(model_name, ' ', '_'))
    INTO v_key_name
    FROM llm_users.models
    WHERE id = p_model_id;
    
    -- Store in vault
    PERFORM store_api_key(v_key_name, v_api_key, 'API key for model ' || p_model_id::text);
    
    RETURN v_api_key;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Register all available models
DO $$
BEGIN
    -- OpenAI Models
    PERFORM register_llm_model(
        'gpt-4-turbo-preview',
        'openai',
        '{"vision": true, "function_calling": true, "json_mode": true}',
        '{"requests_per_minute": 60, "tokens_per_minute": 150000}'
    );
    
    PERFORM register_llm_model(
        'gpt-4',
        'openai',
        '{"vision": false, "function_calling": true, "json_mode": true}',
        '{"requests_per_minute": 60, "tokens_per_minute": 40000}'
    );
    
    PERFORM register_llm_model(
        'gpt-3.5-turbo',
        'openai',
        '{"vision": false, "function_calling": true, "json_mode": true}',
        '{"requests_per_minute": 3500, "tokens_per_minute": 90000}'
    );
    
    -- Anthropic Models
    PERFORM register_llm_model(
        'claude-3-opus',
        'anthropic',
        '{"vision": true, "function_calling": false, "json_mode": false}',
        '{"requests_per_minute": 50, "tokens_per_minute": 100000}'
    );
    
    PERFORM register_llm_model(
        'claude-3-sonnet',
        'anthropic',
        '{"vision": true, "function_calling": false, "json_mode": false}',
        '{"requests_per_minute": 50, "tokens_per_minute": 100000}'
    );
    
    -- Local Models (Ollama)
    PERFORM register_llm_model(
        'llama2',
        'local',
        '{"vision": false, "function_calling": false, "json_mode": false}',
        '{"requests_per_minute": 1000, "tokens_per_minute": 500000}'
    );
    
    PERFORM register_llm_model(
        'mistral',
        'local',
        '{"vision": false, "function_calling": false, "json_mode": false}',
        '{"requests_per_minute": 1000, "tokens_per_minute": 500000}'
    );
    
    PERFORM register_llm_model(
        'codellama',
        'local',
        '{"vision": false, "function_calling": false, "json_mode": false, "code_specialist": true}',
        '{"requests_per_minute": 1000, "tokens_per_minute": 500000}'
    );
    
    -- Voice Models
    PERFORM register_llm_model(
        'whisper-1',
        'openai',
        '{"type": "speech-to-text", "languages": ["en", "es", "fr", "de", "it", "pt", "ru", "ja", "ko"]}',
        '{"requests_per_minute": 50, "audio_minutes_per_day": 1440}'
    );
    
    PERFORM register_llm_model(
        'elevenlabs-rachel',
        'elevenlabs',
        '{"type": "text-to-speech", "voice_profile": "sweet", "gender": "female"}',
        '{"requests_per_minute": 100, "characters_per_month": 100000}'
    );
    
    PERFORM register_llm_model(
        'elevenlabs-bella',
        'elevenlabs',
        '{"type": "text-to-speech", "voice_profile": "confident", "gender": "female"}',
        '{"requests_per_minute": 100, "characters_per_month": 100000}'
    );
END $$;

-- Create view for model usage dashboard
CREATE OR REPLACE VIEW llm_usage_dashboard AS
SELECT 
    m.model_name,
    m.provider,
    m.capabilities,
    m.rate_limits,
    m.usage_stats,
    COUNT(DISTINCT ae.id) as total_requests_24h,
    COALESCE(SUM((ae.metadata->>'tokens_used')::int), 0) as total_tokens_24h,
    COALESCE(AVG((ae.metadata->>'tokens_used')::int), 0) as avg_tokens_per_request,
    MAX(ae.timestamp) as last_used
FROM llm_users.models m
LEFT JOIN analytics_events ae ON ae.llm_model_id = m.id
    AND ae.timestamp > NOW() - INTERVAL '24 hours'
    AND ae.event_type = 'llm_request'
GROUP BY m.id, m.model_name, m.provider, m.capabilities, m.rate_limits, m.usage_stats;

-- Create function to get model recommendations based on task
CREATE OR REPLACE FUNCTION recommend_model_for_task(
    task_type TEXT,
    requirements JSONB DEFAULT '{}'
) RETURNS TABLE (
    model_name TEXT,
    provider TEXT,
    score INT,
    reason TEXT
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        m.model_name,
        m.provider,
        CASE 
            -- Code tasks
            WHEN task_type = 'code' AND m.capabilities->>'code_specialist' = 'true' THEN 100
            WHEN task_type = 'code' AND m.model_name LIKE '%code%' THEN 90
            WHEN task_type = 'code' AND m.provider = 'openai' THEN 80
            
            -- Vision tasks
            WHEN task_type = 'vision' AND m.capabilities->>'vision' = 'true' THEN 100
            
            -- Fast responses
            WHEN task_type = 'fast' AND m.provider = 'local' THEN 100
            WHEN task_type = 'fast' AND m.model_name LIKE '%turbo%' THEN 90
            
            -- Complex reasoning
            WHEN task_type = 'complex' AND m.model_name LIKE '%opus%' THEN 100
            WHEN task_type = 'complex' AND m.model_name LIKE '%gpt-4%' THEN 95
            
            -- Speech tasks
            WHEN task_type = 'speech-to-text' AND m.capabilities->>'type' = 'speech-to-text' THEN 100
            WHEN task_type = 'text-to-speech' AND m.capabilities->>'type' = 'text-to-speech' THEN 100
            
            ELSE 50
        END as score,
        CASE 
            WHEN task_type = 'code' AND m.capabilities->>'code_specialist' = 'true' THEN 'Specialized code model'
            WHEN task_type = 'vision' AND m.capabilities->>'vision' = 'true' THEN 'Supports image analysis'
            WHEN task_type = 'fast' AND m.provider = 'local' THEN 'Local model with no latency'
            WHEN task_type = 'complex' AND m.model_name LIKE '%opus%' THEN 'Best for complex reasoning'
            WHEN task_type = 'speech-to-text' THEN 'Speech recognition model'
            WHEN task_type = 'text-to-speech' THEN 'Voice synthesis model'
            ELSE 'General purpose model'
        END as reason
    FROM llm_users.models m
    WHERE 
        -- Filter by requirements if provided
        (requirements->>'max_cost' IS NULL OR 
         (m.provider = 'local' OR m.model_name LIKE '%3.5%' OR m.model_name LIKE '%sonnet%'))
    ORDER BY score DESC, m.model_name;
END;
$$ LANGUAGE plpgsql;

-- Grant permissions
GRANT EXECUTE ON FUNCTION register_llm_model TO service_role;
GRANT EXECUTE ON FUNCTION create_model_api_key TO service_role;
GRANT EXECUTE ON FUNCTION recommend_model_for_task TO authenticated;
GRANT SELECT ON llm_usage_dashboard TO authenticated;