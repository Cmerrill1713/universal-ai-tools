{
  "local_llm_settings": {
    "preferred_service": "lm-studio",
    "fallback_enabled": true,
    "services": {
      "ollama": {
        "url": "http://localhost:11434",
        "default_model": "codellama:7b",
        "models": {
          "codellama:7b": {
            "tasks": ["code-fix", "completion"],
            "context_length": 16384,
            "preferred_for": ["typescript", "javascript", "python"]
          },
          "llama2:13b": {
            "tasks": ["completion", "analysis"],
            "context_length": 4096,
            "preferred_for": ["general"]
          },
          "mistral:7b": {
            "tasks": ["completion", "reasoning"],
            "context_length": 8192,
            "preferred_for": ["fast-inference"]
          },
          "nomic-embed-text": {
            "tasks": ["embedding"],
            "dimensions": 768,
            "preferred_for": ["general-embedding", "semantic-search"]
          },
          "all-minilm": {
            "tasks": ["embedding"],
            "dimensions": 384,
            "preferred_for": ["lightweight-embedding"]
          },
          "mxbai-embed-large": {
            "tasks": ["embedding"],
            "dimensions": 1024,
            "preferred_for": ["multilingual-embedding"]
          }
        }
      },
      "lm-studio": {
        "url": "http://localhost:5901/v1",
        "default_model": "qwen/qwen3-coder-30b",
        "models": {
          "qwen/qwen3-30b-a3b-2507": {
            "tasks": ["reasoning", "complex-analysis", "long-context"],
            "context_length": 128000,
            "preferred_for": ["complex-reasoning", "long-documents", "analysis"],
            "description": "Qwen 30B - Large context, advanced reasoning"
          },
          "qwen/qwen3-coder-30b": {
            "tasks": ["code-generation", "code-analysis", "debugging"],
            "context_length": 128000,
            "preferred_for": ["typescript", "python", "code-review", "refactoring"],
            "description": "Qwen 30B Coder - Advanced coding with large context"
          },
          "qwen2.5-coder-14b-instruct-mlx": {
            "tasks": ["code-fix", "completion", "code-analysis"],
            "context_length": 32768,
            "preferred_for": ["typescript", "javascript", "fast-coding"],
            "description": "Qwen 14B Coder - MLX optimized for Apple Silicon"
          },
          "openai/gpt-oss-20b": {
            "tasks": ["general-conversation", "analysis", "writing"],
            "context_length": 32768,
            "preferred_for": ["general-purpose", "conversation", "writing"],
            "description": "GPT-style 20B model for general tasks"
          },
          "dolphin-mistral-24b-venice-edition-mlx": {
            "tasks": ["conversation", "creative-writing", "analysis"],
            "context_length": 32768,
            "preferred_for": ["creative-tasks", "conversation", "brainstorming"],
            "description": "Dolphin Mistral 24B - Creative and conversational"
          },
          "google/gemma-3-12b": {
            "tasks": ["analysis", "reasoning", "completion"],
            "context_length": 8192,
            "preferred_for": ["logical-reasoning", "analysis", "structured-thinking"],
            "description": "Google Gemma 12B - Structured reasoning"
          },
          "google/gemma-3-4b": {
            "tasks": ["fast-completion", "simple-analysis"],
            "context_length": 8192,
            "preferred_for": ["quick-responses", "simple-tasks"],
            "description": "Google Gemma 4B - Fast responses"
          },
          "deepseek/deepseek-r1-0528-qwen3-8b": {
            "tasks": ["reasoning", "math", "logic"],
            "context_length": 32768,
            "preferred_for": ["mathematical-reasoning", "logical-analysis"],
            "description": "DeepSeek R1 8B - Advanced reasoning and math"
          },
          "mistralai/mistral-small-3.2": {
            "tasks": ["completion", "chat", "analysis"],
            "context_length": 32768,
            "preferred_for": ["balanced-performance", "general-tasks"],
            "description": "Mistral Small 3.2 - Balanced performance"
          },
          "mistralai/devstral-small-2505": {
            "tasks": ["code-generation", "development", "technical-writing"],
            "context_length": 32768,
            "preferred_for": ["development", "technical-documentation"],
            "description": "Mistral Devstral - Development focused"
          },
          "llama-3.2-1b-instruct": {
            "tasks": ["fast-response", "simple-tasks"],
            "context_length": 8192,
            "preferred_for": ["ultra-fast-responses", "simple-qa"],
            "description": "Llama 3.2 1B - Ultra-fast responses"
          },
          "qwen2.5-0.5b-instruct-mlx": {
            "tasks": ["ultra-fast-response", "routing"],
            "context_length": 4096,
            "preferred_for": ["routing-decisions", "classification"],
            "description": "Qwen 0.5B - Ultra-fast routing and classification"
          },
          "qwen2.5-coder-0.5b-instruct-mlx": {
            "tasks": ["fast-code-completion", "syntax-checking"],
            "context_length": 4096,
            "preferred_for": ["code-completion", "syntax-validation"],
            "description": "Qwen 0.5B Coder - Fast code assistance"
          },
          "deepseek-r1-0528-coder-draft-0.6b-v1.0": {
            "tasks": ["code-drafting", "quick-code-fixes"],
            "context_length": 8192,
            "preferred_for": ["code-drafting", "quick-fixes"],
            "description": "DeepSeek R1 Coder Draft - Quick coding assistance"
          },
          "text-embedding-nomic-embed-text-v1.5": {
            "tasks": ["embedding"],
            "dimensions": 768,
            "context_length": 8192,
            "preferred_for": ["general-embedding", "semantic-search"],
            "description": "Nomic Embed - High-quality text embeddings"
          }
        }
      }
    },
    "routing_rules": [
      {
        "name": "complex-reasoning-to-qwen-30b",
        "condition": {
          "task": "complex-analysis",
          "requires_reasoning": true
        },
        "prefer_models": [
          "lm-studio:qwen/qwen3-30b-a3b-2507",
          "lm-studio:deepseek/deepseek-r1-0528-qwen3-8b"
        ]
      },
      {
        "name": "coding-to-specialized-models",
        "condition": {
          "task": "code-generation",
          "language": ["typescript", "python", "javascript"]
        },
        "prefer_models": [
          "lm-studio:qwen/qwen3-coder-30b",
          "lm-studio:qwen2.5-coder-14b-instruct-mlx",
          "lm-studio:mistralai/devstral-small-2505"
        ]
      },
      {
        "name": "fast-code-assistance",
        "condition": {
          "task": "code-completion",
          "constraint": "low-latency"
        },
        "prefer_models": [
          "lm-studio:qwen2.5-coder-0.5b-instruct-mlx",
          "lm-studio:deepseek-r1-0528-coder-draft-0.6b-v1.0"
        ]
      },
      {
        "name": "embeddings-to-nomic",
        "condition": {
          "task": "embedding"
        },
        "prefer_models": [
          "lm-studio:text-embedding-nomic-embed-text-v1.5",
          "ollama:nomic-embed-text"
        ]
      },
      {
        "name": "ultra-fast-responses",
        "condition": {
          "constraint": "ultra-low-latency"
        },
        "prefer_models": [
          "lm-studio:qwen2.5-0.5b-instruct-mlx",
          "lm-studio:llama-3.2-1b-instruct"
        ]
      },
      {
        "name": "creative-tasks",
        "condition": {
          "task": "creative-writing",
          "requires_creativity": true
        },
        "prefer_models": [
          "lm-studio:dolphin-mistral-24b-venice-edition-mlx",
          "lm-studio:qwen/qwen3-30b-a3b-2507"
        ]
      },
      {
        "name": "long-context-analysis",
        "condition": {
          "context_length": ">32000"
        },
        "prefer_models": [
          "lm-studio:qwen/qwen3-30b-a3b-2507",
          "lm-studio:qwen/qwen3-coder-30b"
        ]
      }
    ],
    "performance_settings": {
      "cache_embeddings": true,
      "cache_ttl_seconds": 3600,
      "max_concurrent_requests": 5,
      "timeout_seconds": 180,
      "retry_attempts": 3,
      "context_awareness": {
        "auto_adjust_context": true,
        "max_context_utilization": 0.9,
        "context_overflow_strategy": "truncate_middle"
      },
      "model_selection": {
        "prefer_mlx_on_apple_silicon": true,
        "fallback_enabled": true,
        "load_balancing": "round_robin"
      }
    }
  }
}