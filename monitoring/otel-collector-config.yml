receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins:
            - "*"
          allowed_headers:
            - "*"
  
  # HTTP receiver for custom metrics
  prometheus:
    config:
      scrape_configs:
        - job_name: 'universal-ai-tools'
          static_configs:
            - targets: ['app:9999']
          scrape_interval: 15s
          metrics_path: '/metrics'

  # Jaeger receiver for legacy traces
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
      thrift_compact:
        endpoint: 0.0.0.0:6831
      thrift_binary:
        endpoint: 0.0.0.0:6832

  # Zipkin receiver
  zipkin:
    endpoint: 0.0.0.0:9411

processors:
  # Batch processor to optimize export
  batch:
    timeout: 5s
    send_batch_size: 1024
    send_batch_max_size: 2048

  # Memory limiter to prevent OOM
  memory_limiter:
    limit_mib: 512
    spike_limit_mib: 128
    check_interval: 5s

  # Resource processor to add service info
  resource:
    attributes:
      - key: service.name
        value: universal-ai-tools
        action: upsert
      - key: service.version
        value: 1.0.0
        action: upsert
      - key: deployment.environment
        value: development
        action: upsert

  # Probabilistic sampler for high-volume traces
  probabilistic_sampler:
    sampling_percentage: 100  # 100% for development, reduce for production

  # Attribute processor for custom enrichment
  attributes:
    actions:
      - key: ai.service
        action: upsert
        value: universal-ai-tools
      - key: telemetry.sdk.name
        action: upsert
        value: opentelemetry

exporters:
  # OTLP exporter for Jaeger
  otlp/jaeger:
    endpoint: jaeger:4317
    tls:
      insecure: true

  # Zipkin exporter
  zipkin:
    endpoint: http://zipkin:9411/api/v2/spans
    format: json

  # Prometheus exporter
  prometheus:
    endpoint: "0.0.0.0:8888"
    namespace: "universal_ai_tools"
    const_labels:
      service: "universal-ai-tools"

  # OTLP HTTP exporter
  otlphttp:
    endpoint: http://jaeger:14268/api/traces
    tls:
      insecure: true

  # Logging exporter for debugging
  logging:
    loglevel: debug
    sampling_initial: 5
    sampling_thereafter: 200

  # File exporter for backup
  file:
    path: /tmp/otel-traces.json

extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133

  # pprof extension for profiling
  pprof:
    endpoint: 0.0.0.0:1777

  # zpages extension for diagnostics
  zpages:
    endpoint: 0.0.0.0:55679

service:
  extensions: [health_check, pprof, zpages]
  
  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp, jaeger, zipkin]
      processors: [memory_limiter, resource, attributes, probabilistic_sampler, batch]
      exporters: [otlp/jaeger, zipkin, otlphttp, logging]

    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus]
      processors: [memory_limiter, resource, batch]
      exporters: [prometheus, logging]

    # Logs pipeline (when available)
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resource, batch]
      exporters: [logging]

  telemetry:
    logs:
      level: "debug"
    metrics:
      address: 0.0.0.0:8889