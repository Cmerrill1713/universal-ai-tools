{
  "dashboard": {
    "id": null,
    "title": "Universal AI Tools - System Performance",
    "tags": ["system", "performance", "monitoring", "universal-ai-tools"],
    "style": "dark",
    "timezone": "browser",
    "editable": true,
    "graphTooltip": 1,
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "timepicker": {
      "refresh_intervals": ["5s", "10s", "30s", "1m", "5m", "15m", "30m", "1h"],
      "time_options": ["5m", "15m", "1h", "6h", "12h", "24h", "2d", "7d", "30d"]
    },
    "refresh": "30s",
    "version": 1,
    "panels": [
      {
        "id": 1,
        "title": "System Overview",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"api\"}",
            "legendFormat": "API Status",
            "refId": "A"
          },
          {
            "expr": "service_uptime_seconds{service_name=\"universal-ai-tools\"}",
            "legendFormat": "Uptime (s)",
            "refId": "B"
          },
          {
            "expr": "system_health_score",
            "legendFormat": "Health Score",
            "refId": "C"
          },
          {
            "expr": "rate(http_requests_total[5m]) * 60",
            "legendFormat": "Requests/min",
            "refId": "D"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "short",
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {
                  "color": "red",
                  "value": 0
                },
                {
                  "color": "yellow",
                  "value": 50
                },
                {
                  "color": "green",
                  "value": 80
                }
              ]
            }
          }
        },
        "gridPos": {
          "h": 6,
          "w": 24,
          "x": 0,
          "y": 0
        }
      },
      {
        "id": 2,
        "title": "API Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m]) * 60",
            "legendFormat": "Total requests/min",
            "refId": "A"
          },
          {
            "expr": "rate(http_requests_total{status_code=~\"2..\"}[5m]) * 60",
            "legendFormat": "Success (2xx)",
            "refId": "B"
          },
          {
            "expr": "rate(http_requests_total{status_code=~\"4..\"}[5m]) * 60",
            "legendFormat": "Client errors (4xx)",
            "refId": "C"
          },
          {
            "expr": "rate(http_requests_total{status_code=~\"5..\"}[5m]) * 60",
            "legendFormat": "Server errors (5xx)",
            "refId": "D"
          }
        ],
        "yAxes": [
          {
            "unit": "reqps",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 6
        }
      },
      {
        "id": 3,
        "title": "Response Time Distribution",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile",
            "refId": "A"
          },
          {
            "expr": "histogram_quantile(0.75, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "75th percentile",
            "refId": "B"
          },
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile (median)",
            "refId": "C"
          },
          {
            "expr": "rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])",
            "legendFormat": "Average",
            "refId": "D"
          }
        ],
        "yAxes": [
          {
            "unit": "s",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 6
        }
      },
      {
        "id": 4,
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "memory_usage_bytes{type=\"heap_used\"} / 1024 / 1024",
            "legendFormat": "Heap Used (MB)",
            "refId": "A"
          },
          {
            "expr": "memory_usage_bytes{type=\"heap_total\"} / 1024 / 1024",
            "legendFormat": "Heap Total (MB)",
            "refId": "B"
          },
          {
            "expr": "memory_usage_bytes{type=\"rss\"} / 1024 / 1024",
            "legendFormat": "RSS (MB)",
            "refId": "C"
          },
          {
            "expr": "memory_usage_bytes{type=\"external\"} / 1024 / 1024",
            "legendFormat": "External (MB)",
            "refId": "D"
          }
        ],
        "yAxes": [
          {
            "unit": "mbytes",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 14
        }
      },
      {
        "id": 5,
        "title": "CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "cpu_usage_percent",
            "legendFormat": "CPU Usage %",
            "refId": "A"
          },
          {
            "expr": "avg(rate(cpu_usage_percent[5m])) * 100",
            "legendFormat": "Average CPU %",
            "refId": "B"
          }
        ],
        "yAxes": [
          {
            "unit": "percent",
            "min": 0,
            "max": 100
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 14
        }
      },
      {
        "id": 6,
        "title": "Database Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(database_query_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile query time",
            "refId": "A"
          },
          {
            "expr": "rate(database_query_duration_seconds_sum[5m]) / rate(database_query_duration_seconds_count[5m])",
            "legendFormat": "Average query time",
            "refId": "B"
          },
          {
            "expr": "database_connections_active",
            "legendFormat": "Active connections",
            "refId": "C"
          },
          {
            "expr": "rate(database_errors_total[5m]) * 60",
            "legendFormat": "Errors per minute",
            "refId": "D"
          }
        ],
        "yAxes": [
          {
            "unit": "s",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 24,
          "x": 0,
          "y": 22
        }
      },
      {
        "id": 7,
        "title": "Memory System Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(memory_operations_total[5m]) * 60",
            "legendFormat": "Operations per minute - {{operation_type}}",
            "refId": "A"
          },
          {
            "expr": "histogram_quantile(0.95, rate(memory_query_time_seconds_bucket[5m]))",
            "legendFormat": "95th percentile query time",
            "refId": "B"
          },
          {
            "expr": "memory_storage_size_bytes / 1024 / 1024",
            "legendFormat": "Storage size (MB) - {{memory_type}}",
            "refId": "C"
          }
        ],
        "yAxes": [
          {
            "unit": "short",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 24,
          "x": 0,
          "y": 30
        }
      },
      {
        "id": 8,
        "title": "AI Model Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(ai_model_inference_time_seconds_bucket[5m]))",
            "legendFormat": "95th percentile inference time - {{model_name}}",
            "refId": "A"
          },
          {
            "expr": "rate(ai_model_tokens_processed_total[5m]) * 60",
            "legendFormat": "Tokens/min - {{model_name}} {{direction}}",
            "refId": "B"
          },
          {
            "expr": "ai_model_memory_usage_bytes / 1024 / 1024",
            "legendFormat": "Model memory (MB) - {{model_name}}",
            "refId": "C"
          }
        ],
        "yAxes": [
          {
            "unit": "short",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 24,
          "x": 0,
          "y": 38
        }
      },
      {
        "id": 9,
        "title": "Error Rate by Component",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(database_errors_total[5m]) * 60",
            "legendFormat": "Database errors/min - {{table}}",
            "refId": "A"
          },
          {
            "expr": "rate(http_requests_total{status_code=~\"5..\"}[5m]) * 60",
            "legendFormat": "HTTP 5xx errors/min - {{route}}",
            "refId": "B"
          },
          {
            "expr": "error_rate_percent",
            "legendFormat": "Error rate % - {{component}}",
            "refId": "C"
          }
        ],
        "yAxes": [
          {
            "unit": "short",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 46
        }
      },
      {
        "id": 10,
        "title": "Security Events",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(security_events_total[5m]) * 60",
            "legendFormat": "Security events/min - {{event_type}} ({{severity}})",
            "refId": "A"
          },
          {
            "expr": "rate(authentication_attempts_total{status=\"failed\"}[5m]) * 60",
            "legendFormat": "Failed auth attempts/min",
            "refId": "B"
          },
          {
            "expr": "rate(rate_limit_hits_total[5m]) * 60",
            "legendFormat": "Rate limit hits/min - {{endpoint}}",
            "refId": "C"
          }
        ],
        "yAxes": [
          {
            "unit": "short",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 46
        }
      },
      {
        "id": 11,
        "title": "Request Size Distribution",
        "type": "heatmap",
        "targets": [
          {
            "expr": "sum by (le) (rate(http_request_size_bytes_bucket[5m]))",
            "legendFormat": "{{le}}",
            "refId": "A"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 54
        },
        "options": {
          "calculate": false,
          "cellGap": 2,
          "color": {
            "exponent": 0.5,
            "fill": "dark-orange",
            "mode": "spectrum",
            "scale": "exponential",
            "scheme": "Blues",
            "steps": 64
          }
        }
      },
      {
        "id": 12,
        "title": "Response Size Distribution",
        "type": "heatmap",
        "targets": [
          {
            "expr": "sum by (le) (rate(http_response_size_bytes_bucket[5m]))",
            "legendFormat": "{{le}}",
            "refId": "A"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 54
        },
        "options": {
          "calculate": false,
          "cellGap": 2,
          "color": {
            "exponent": 0.5,
            "fill": "dark-orange",
            "mode": "spectrum",
            "scale": "exponential",
            "scheme": "Greens",
            "steps": 64
          }
        }
      }
    ],
    "templating": {
      "list": [
        {
          "allValue": null,
          "current": {
            "text": "All",
            "value": "$__all"
          },
          "datasource": "Prometheus",
          "definition": "label_values(http_requests_total, ai_service)",
          "hide": 0,
          "includeAll": true,
          "label": "AI Service",
          "multi": true,
          "name": "ai_service",
          "options": [],
          "query": "label_values(http_requests_total, ai_service)",
          "refresh": 1,
          "regex": "",
          "skipUrlSync": false,
          "sort": 1,
          "type": "query"
        },
        {
          "allValue": null,
          "current": {
            "text": "All",
            "value": "$__all"
          },
          "datasource": "Prometheus",
          "definition": "label_values(http_requests_total, route)",
          "hide": 0,
          "includeAll": true,
          "label": "Route",
          "multi": true,
          "name": "route",
          "options": [],
          "query": "label_values(http_requests_total, route)",
          "refresh": 1,
          "regex": "",
          "skipUrlSync": false,
          "sort": 1,
          "type": "query"
        }
      ]
    },
    "annotations": {
      "list": [
        {
          "builtIn": 1,
          "datasource": "-- Grafana --",
          "enable": true,
          "hide": true,
          "iconColor": "rgba(0, 211, 255, 1)",
          "name": "Annotations & Alerts",
          "type": "dashboard"
        }
      ]
    },
    "description": "System performance monitoring for Universal AI Tools including API metrics, resource usage, database performance, and error tracking.",
    "gnetId": null,
    "version": 1
  }
}