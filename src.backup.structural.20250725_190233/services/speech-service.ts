import type { SupabaseClient } from '@supabase/supabase-js';
import OpenAI from 'openai';
import FormData from 'form-data';
import fs from 'fs';
import axios from 'axios';
import { LogContext, logger } from '../utils/enhanced-logger';
import { config } from '../config';
import { type KokoroVoiceProfile, kokoroTTS } from './kokoro-tts-service';
import { audioHandler } from './audio-handler';
interface TranscriptionResult {;
  text: string;
  duration?: number;
  confidence?: number;
  language?: string;
;
};

interface SynthesisOptions {;
  text: string;
  voiceProfile: VoiceProfile;
  voiceSettings?: VoiceSettings;
  format: 'mp3' | 'wav';
;
};

interface VoiceProfile {;
  voice_id: string;
  pitch: number;
  speaking_rate: number;
  stability: number;
  similarity_boost: number;
  style: number;
  use_speaker_boost: boolean;
;
};

interface VoiceSettings {;
  stability?: number;
  similarity_boost?: number;
  style?: number;
  use_speaker_boost?: boolean;
;
};

interface AudioResult {;
  buffer: Buffer;
  mimeType: string;
  voice_id: string;
  duration: number;
;
};

/**;
 * SpeechService provides comprehensive voice synthesis and speech recognition capabilities.;
 * Supports multiple TTS providers (OpenAI, ElevenLabs, Kokoro) with automatic fallback.;
 *;
 * Features:;
 * - Multi-provider TTS with quality optimization;
 * - Whisper-based speech recognition;
 * - Personality-based voice modulation;
 * - Automatic provider fallback;
 * - Development mode mock responses;
 */;
export class SpeechService {;
  private openai: OpenAI | null = null;
  private elevenLabsApiKey: string | null;
  private whisperApiUrl: string;
  constructor(private supabase: SupabaseClient) {;
    // Initialize OpenAI for Whisper transcription and TTS if API key is available;
    const openaiApiKey = processenvOPENAI_API_KEY;
    if (openaiApiKey) {;
      thisopenai = new OpenAI({ apiKey: openaiApiKey });
    };

    // ElevenLabs configuration for premium voice synthesis;
    thiselevenLabsApiKey = processenvELEVENLABS_API_KEY || null;
    // Whisper API URL (supports both local and cloud deployments);
    thiswhisperApiUrl =;
      processenvWHISPER_API_URL || 'https: //apiopenaicom/v1/audio/transcriptions';
  ;
};

  /**;
   * Transcribes audio files to text using available speech recognition services.;
   * Implements provider fallback: OpenAI Whisper -> Local Whisper -> Mock (dev);
   *;
   * @param filePath - Path to the audio file to transcribe;
   * @param mimeType - MIME type of the audio file;
   * @param context - Optional context to improve transcription accuracy;
   * @returns Promise<TranscriptionResult> with text, confidence, duration, and language;
   */;
  async transcribeAudio(;
    filePath: string;
    mimeType: string;
    context?: string;
  ): Promise<TranscriptionResult> {;
    try {;
      // Try OpenAI Whisper first (highest quality);
      if (thisopenai) {;
        return await thistranscribeWithOpenAI(filePath, context);
      };

      // Fallback to local Whisper deployment;
      return await thistranscribeWithLocalWhisper(filePath, context);
    } catch (error instanceof Error ? errormessage : String(error) any) {;
      loggererror('Transcription error instanceof Error ? errormessage : String(error)  LogContextAVATAR, { error instanceof Error ? errormessage : String(error));
      // Fallback to mock transcription for development;
      if (configserverisDevelopment) {;
        loggerwarn('Using mock transcription in development mode', LogContextAVATAR);
        return {;
          text: 'This is a mock transcription for development purposes.';
          confidence: 0.95;
          duration: 5.0;
          language: 'en';
        ;
};
      };

      throw error instanceof Error ? errormessage : String(error);
    };
  };

  private async transcribeWithOpenAI(;
    filePath: string;
    context?: string;
  ): Promise<TranscriptionResult> {;
    if (!thisopenai) {;
      throw new Error('OpenAI client not initialized');
    };

    const formData = new FormData();
    formDataappend('file', fscreateReadStream(filePath));
    formDataappend('model', 'whisper-1');
    if (context) {;
      formDataappend('prompt', context);
    };

    try {;
      const response = await axiospost(;
        'https://apiopenaicom/v1/audio/transcriptions';
        formData;
        {;
          headers: {;
            ..formDatagetHeaders();
            Authorization: `Bearer ${processenvOPENAI_API_KEY}`;
          };
        };
      );
      return {;
        text: responsedatatext;
        confidence: 0.95, // OpenAI doesn't provide confidence scores;
        language: responsedatalanguage || 'en';
      ;
};
    } catch (error instanceof Error ? errormessage : String(error) any) {;
      loggererror('OpenAI Whisper error instanceof Error ? errormessage : String(error)  LogContextAVATAR, { error instanceof Error ? errormessage : String(error));
      throw new Error('Failed to transcribe with OpenAI Whisper');
    };
  };

  private async transcribeWithLocalWhisper(;
    filePath: string;
    context?: string;
  ): Promise<TranscriptionResult> {;
    // This would integrate with a local Whisper instance;
    // For now, we'll use a placeholder implementation;

    try {;
      // You would implement actual local Whisper integration here;
      // For example, using whispercpp or a Python service;

      const mockResponse = {;
        text: 'Local Whisper transcription not yet implemented';
        confidence: 0.8;
        duration: 3.0;
        language: 'en';
      };
      return mockResponse;
    } catch (error instanceof Error ? errormessage : String(error) any) {;
      loggererror('Local Whisper error instanceof Error ? errormessage : String(error)  LogContextAVATAR, { error instanceof Error ? errormessage : String(error));
      throw new Error('Failed to transcribe with local Whisper');
    };
  };

  async synthesizeSpeech(options: SynthesisOptions): Promise<AudioResult> {;
    try {;
      // Try ElevenLabs first for high-quality voice;
      if (thiselevenLabsApiKey) {;
        return await thissynthesizeWithElevenLabs(options);
      };

      // Fallback to OpenAI TTS;
      if (thisopenai) {;
        return await thissynthesizeWithOpenAI(options);
      };

      // Fallback to local TTS;
      return await thissynthesizeWithLocalTTS(options);
    } catch (error instanceof Error ? errormessage : String(error) any) {;
      loggererror('Synthesis error instanceof Error ? errormessage : String(error)  LogContextAVATAR, { error instanceof Error ? errormessage : String(error));
      // Fallback to mock audio for development;
      if (configserverisDevelopment) {;
        loggerwarn('Using mock audio in development mode', LogContextAVATAR);
        return thisgenerateMockAudio(options);
      };

      throw error instanceof Error ? errormessage : String(error);
    };
  };

  private async synthesizeWithElevenLabs(options: SynthesisOptions): Promise<AudioResult> {;
    if (!thiselevenLabsApiKey) {;
      throw new Error('ElevenLabs API key not configured');
    };

    const voiceId = optionsvoiceProfilevoice_id;
    const url = `https://apielevenlabsio/v1/text-to-speech/${voiceId}`;
    try {;
      const response = await axiospost(;
        url;
        {;
          text: optionstext;
          model_id: 'eleven_turbo_v2';
          voice_settings: {;
            stability: optionsvoiceSettings?stability || optionsvoiceProfilestability;
            similarity_boost:;
              optionsvoiceSettings?similarity_boost || optionsvoiceProfilesimilarity_boost;
            style: optionsvoiceSettings?style || optionsvoiceProfilestyle;
            use_speaker_boost:;
              optionsvoiceSettings?use_speaker_boost || optionsvoiceProfileuse_speaker_boost;
          ;
};
        };
        {;
          headers: {;
            Accept: optionsformat === 'mp3' ? 'audio/mpeg' : 'audio/wav';
            'xi-api-key': thiselevenLabsApiKey;
            'Content-Type': 'application/json';
          ;
};
          responseType: 'arraybuffer';
        ;
};
      );
      const buffer = Bufferfrom(responsedata);
      // Validate and process the audio;
      const validation = await audioHandlervalidateAudioBuffer(buffer, optionsformat);
      if (!validationisValid) {;
        loggerwarn('ElevenLabs audio validation issues', LogContextAVATAR, {;
          errors: validationerrors;
        });
      };

      // Process audio for optimization;
      const audioProcessingResult = await audioHandlerprocessAudio(buffer, {;
        format: optionsformat;
        normalize: true;
        removeNoise: false;
      });
      return {;
        buffer: audioProcessingResultbuffer;
        mimeType: optionsformat === 'mp3' ? 'audio/mpeg' : 'audio/wav';
        voice_id: voiceId;
        duration: audioProcessingResultmetadataduration;
      ;
};
    } catch (error instanceof Error ? errormessage : String(error) any) {;
      loggererror('ElevenLabs synthesis error instanceof Error ? errormessage : String(error)  LogContextAVATAR, { error instanceof Error ? errormessage : String(error));
      throw new Error('Failed to synthesize with ElevenLabs');
    };
  };

  private async synthesizeWithOpenAI(options: SynthesisOptions): Promise<AudioResult> {;
    if (!thisopenai) {;
      throw new Error('OpenAI client not initialized');
    };

    try {;
      // Map personality to OpenAI voices;
      const voiceMap: Record<string, string> = {;
        sweet: 'nova', // Warm and friendly;
        shy: 'shimmer', // Soft and gentle;
        confident: 'alloy', // Clear and assured;
        caring: 'echo', // Soothing and nurturing;
        playful: 'fable', // Expressive and lively;
      };
      const voice = voiceMap[optionsvoiceProfilevoice_id] || 'nova';
      const response = await axiospost(;
        'https: //apiopenaicom/v1/audio/speech';
        {;
          model: 'tts-1-hd';
          voice;
          inputoptionstext;
          response_format: optionsformat;
          speed: optionsvoiceProfilespeaking_rate;
        ;
};
        {;
          headers: {;
            Authorization: `Bearer ${processenvOPENAI_API_KEY}`;
            'Content-Type': 'application/json';
          ;
};
          responseType: 'arraybuffer';
        ;
};
      );
      const buffer = Bufferfrom(responsedata);
      // Validate and process OpenAI audio;
      const validation = await audioHandlervalidateAudioBuffer(buffer, optionsformat);
      if (!validationisValid) {;
        loggerwarn('OpenAI audio validation issues', LogContextAVATAR, {;
          errors: validationerrors;
        });
      };

      // Process audio for optimization;
      const audioProcessingResult = await audioHandlerprocessAudio(buffer, {;
        format: optionsformat;
        normalize: true;
        removeNoise: false;
      });
      return {;
        buffer: audioProcessingResultbuffer;
        mimeType: optionsformat === 'mp3' ? 'audio/mpeg' : 'audio/wav';
        voice_id: voice;
        duration: audioProcessingResultmetadataduration;
      ;
};
    } catch (error instanceof Error ? errormessage : String(error) any) {;
      loggererror('OpenAI TTS error instanceof Error ? errormessage : String(error)  LogContextAVATAR, { error instanceof Error ? errormessage : String(error));
      throw new Error('Failed to synthesize with OpenAI');
    };
  };

  private async synthesizeWithLocalTTS(options: SynthesisOptions): Promise<AudioResult> {;
    try {;
      // Try Kokoro TTS first;
      return await thissynthesizeWithKokoro(options);
    } catch (error) {;
      loggererror('Kokoro TTS failed', LogContextAVATAR, { error instanceof Error ? errormessage : String(error));
      loggerwarn('Falling back to mock audio generation', LogContextAVATAR);
      return thisgenerateMockAudio(options);
    };
  };

  private async synthesizeWithKokoro(options: SynthesisOptions): Promise<AudioResult> {;
    try {;
      // Initialize Kokoro TTS if not already done;
      await kokoroTTSinitialize();
      // Map personality-based voice profile to Kokoro voice;
      const kokoroProfile = thismapToKokoroProfile(optionsvoiceProfile);
      loggerinfo(`Synthesizing with Kokoro TTS: ${kokoroProfileid}`, LogContextAVATAR, {;
        textLength: optionstextlength;
        format: optionsformat;
        personality: kokoroProfilestyle;
      });
      const audioBuffer = await kokoroTTSsynthesize({;
        text: optionstext;
        voiceProfile: kokoroProfile;
        outputFormat: optionsformat;
        temperature: 0.7;
        topP: 0.9;
        tokenLength: Mathmin(200, optionstextsplit(/\s+/)length);
      });
      // Validate the generated audio;
      const isValidAudio = await kokoroTTSvalidateAudioBuffer(audioBuffer, optionsformat);
      if (!isValidAudio) {;
        throw new Error(`Generated audio buffer is invalid for format: ${optionsformat}`);
      };

      // Process audio with comprehensive errorhandling;
      const audioProcessingResult = await audioHandlerprocessAudio(audioBuffer, {;
        format: optionsformat;
        normalize: true;
        removeNoise: false, // Disable for TTS as it's already clean;
      });
      const optimizedBuffer = audioProcessingResultbuffer;
      const { metadata } = audioProcessingResult;
      // Log any processing warnings;
      if (audioProcessingResultwarningslength > 0) {;
        loggerwarn('Audio processing warnings', LogContextAVATAR, {;
          warnings: audioProcessingResultwarnings;
        });
      };

      loggerinfo('Kokoro TTS synthesis completed successfully', LogContextAVATAR, {;
        duration: metadataduration;
        format: metadataformat;
        bufferSize: optimizedBufferlength;
      });
      return {;
        buffer: optimizedBuffer;
        mimeType: optionsformat === 'mp3' ? 'audio/mpeg' : 'audio/wav';
        voice_id: kokoroProfileid;
        duration: metadataduration;
      ;
};
    } catch (error) {;
      loggererror('Kokoro TTS synthesis error instanceof Error ? errormessage : String(error)  LogContextAVATAR, { error instanceof Error ? errormessage : String(error));
      throw new Error(;
        `Kokoro TTS failed: ${error instanceof Error ? errormessage : 'Unknown error instanceof Error ? errormessage : String(error)`;
      );
    ;
};
  };

  private mapToKokoroProfile(voiceProfile: VoiceProfile): KokoroVoiceProfile {;
    const kokoroProfiles = kokoroTTSgetVoiceProfiles();
    // Map voice_id to appropriate Kokoro profile;
    const profileMap: Record<string, string> = {;
      sweet: 'athena-sweet';
      shy: 'athena-sweet', // Map shy to sweet;
      confident: 'athena-confident';
      caring: 'athena-warm';
      playful: 'athena-playful';
      professional: 'athena-professional';
    ;
};
    const kokoroProfileId = profileMap[voiceProfilevoice_id] || 'athena-sweet';
    const kokoroProfile = kokoroProfilesfind((p) => pid === kokoroProfileId);
    if (!kokoroProfile) {;
      // Return default profile if not found;
      return kokoroProfiles[0];
    };

    // Apply voice settings to Kokoro profile;
    return {;
      ..kokoroProfile;
      pitch: voiceProfilepitch || kokoroProfilepitch;
      speed: voiceProfilespeaking_rate || kokoroProfilespeed;
    ;
};
  };

  private generateMockAudio(options: SynthesisOptions): AudioResult {;
    // Generate a simple sine wave as mock audio;
    const sampleRate = 44100;
    const duration = 3; // seconds;
    const frequency = 440; // A4 note;
    const numSamples = sampleRate * duration;
    const buffer = Bufferalloc(numSamples * 2); // 16-bit samples;

    for (let i = 0; i < numSamples; i++) {;
      const sample = Mathsin((2 * MathPI * frequency * i) / sampleRate) * 0.3;
      const value = Mathfloor(sample * 32767);
      bufferwriteInt16LE(value, i * 2);
    };

    return {;
      buffer;
      mimeType: optionsformat === 'mp3' ? 'audio/mpeg' : 'audio/wav';
      voice_id: 'mock';
      duration;
    ;
};
  };

  private estimateAudioDurationFromBuffer(buffer: Buffer, format: string): number {;
    // Very rough estimation based on file size;
    // Actual implementation would parse audio headers;
    const bytesPerSecond = format === 'mp3' ? 16000 : 88200; // Rough estimates;
    return bufferlength / bytesPerSecond;
  };

  async getAvailableVoices(): Promise<any[]> {;
    const voices = [];
    // Add Kokoro voices first (highest priority for local TTS);
    try {;
      const kokoroProfiles = kokoroTTSgetVoiceProfiles();
      voicespush(;
        ..kokoroProfilesmap((profile) => ({;
          id: profileid;
          name: profilename;
          provider: 'kokoro';
          description: `${profilestyle} female voice`;
          gender: profilegender;
          style: profilestyle;
          pitch: profilepitch;
          speed: profilespeed;
          local: true;
        }));
      );
    } catch (error) {;
      loggererror('Failed to fetch Kokoro voices', LogContextAVATAR, { error instanceof Error ? errormessage : String(error) );
    ;
};

    // Add ElevenLabs voices if available;
    if (thiselevenLabsApiKey) {;
      try {;
        const response = await axiosget('https://apielevenlabsio/v1/voices', {;
          headers: { 'xi-api-key': thiselevenLabsApiKey ;
};
        });
        voicespush(;
          ..responsedatavoicesmap((voice: any) => ({;
            id: voicevoice_id;
            name: voicename;
            provider: 'elevenlabs';
            preview_url: voicepreview_url;
            labels: voicelabels;
            local: false;
          }));
        );
      } catch (error) {;
        loggererror('Failed to fetch ElevenLabs voices', LogContextAVATAR, { error instanceof Error ? errormessage : String(error) );
      ;
};
    };

    // Add OpenAI voices;
    if (thisopenai) {;
      voicespush(;
        {;
          id: 'nova';
          name: 'Nova (Sweet)';
          provider: 'openai';
          description: 'Warm and friendly';
          local: false;
        ;
};
        {;
          id: 'shimmer';
          name: 'Shimmer (Shy)';
          provider: 'openai';
          description: 'Soft and gentle';
          local: false;
        ;
};
        {;
          id: 'alloy';
          name: 'Alloy (Confident)';
          provider: 'openai';
          description: 'Clear and assured';
          local: false;
        ;
};
        {;
          id: 'echo';
          name: 'Echo (Caring)';
          provider: 'openai';
          description: 'Soothing and nurturing';
          local: false;
        ;
};
        {;
          id: 'fable';
          name: 'Fable (Playful)';
          provider: 'openai';
          description: 'Expressive and lively';
          local: false;
        ;
};
      );
    };

    // Add local/mock voices for development;
    if (configserverisDevelopment) {;
      voicespush(;
        { id: 'mock-sweet', name: 'Mock Sweet Voice', provider: 'mock', local: true ;
};
        { id: 'mock-confident', name: 'Mock Confident Voice', provider: 'mock', local: true ;
};
      );
    };

    return voices;
  };

  async testKokoroVoice(voiceId: string, sampleText?: string): Promise<Buffer> {;
    try {;
      await kokoroTTSinitialize();
      return await kokoroTTStestVoice(voiceId, sampleText);
    } catch (error) {;
      loggererror('Kokoro voice test failed', LogContextAVATAR, { error instanceof Error ? errormessage : String(error));
      throw error instanceof Error ? errormessage : String(error);
    };
  };

  async getServiceHealth(): Promise<{;
    status: 'healthy' | 'degraded' | 'unhealthy';
    services: {;
      openai: boolean;
      elevenlabs: boolean;
      kokoro: boolean;
      whisper: boolean;
    ;
};
    details: any;
  }> {;
    const health = {;
      status: 'healthy' as 'healthy' | 'degraded' | 'unhealthy';
      services: {;
        openai: false;
        elevenlabs: false;
        kokoro: false;
        whisper: false;
      };
      details: {} as any;
    };
    // Test OpenAI availability;
    try {;
      if (thisopenai) {;
        // Simple test to check if OpenAI is responsive;
        healthservicesopenai = true;
        healthdetailsopenai = { available: true ;
};
      };
    } catch (error) {;
      healthdetailsopenai = {;
        available: false;
        error instanceof Error ? errormessage : String(error) error instanceof Error ? errormessage : 'Unknown error instanceof Error ? errormessage : String(error);
      ;
};
    };

    // Test ElevenLabs availability;
    try {;
      if (thiselevenLabsApiKey) {;
        // Could make a simple API call to test connectivity;
        healthserviceselevenlabs = true;
        healthdetailselevenlabs = { available: true ;
};
      };
    } catch (error) {;
      healthdetailselevenlabs = {;
        available: false;
        error instanceof Error ? errormessage : String(error) error instanceof Error ? errormessage : 'Unknown error instanceof Error ? errormessage : String(error);
      ;
};
    };

    // Test Kokoro TTS availability;
    try {;
      const kokoroStatus = kokoroTTSgetServiceStatus();
      healthserviceskokoro = kokoroStatusinitialized;
      healthdetailskokoro = kokoroStatus;
    } catch (error) {;
      healthdetailskokoro = {;
        available: false;
        error instanceof Error ? errormessage : String(error) error instanceof Error ? errormessage : 'Unknown error instanceof Error ? errormessage : String(error);
      ;
};
    };

    // Test Whisper availability;
    try {;
      healthserviceswhisper = !!thisopenai || !!thiswhisperApiUrl;
      healthdetailswhisper = {;
        available: healthserviceswhisper;
        apiUrl: thiswhisperApiUrl;
      ;
};
    } catch (error) {;
      healthdetailswhisper = {;
        available: false;
        error instanceof Error ? errormessage : String(error) error instanceof Error ? errormessage : 'Unknown error instanceof Error ? errormessage : String(error);
      ;
};
    };

    // Add audio processing stats;
    try {;
      const audioStats = audioHandlergetProcessingStats();
      healthdetailsaudioProcessing = {;
        totalProcessed: audioStatstotalProcessed;
        successRate: audioStatssuccessRate;
        averageProcessingTime: audioStatsaverageProcessingTime;
      ;
};
    } catch (error) {;
      healthdetailsaudioProcessing = {;
        available: false;
        error instanceof Error ? errormessage : String(error) error instanceof Error ? errormessage : 'Unknown error instanceof Error ? errormessage : String(error);
      ;
};
    };

    // Determine overall status;
    const availableServices = Objectvalues(healthservices)filter(Boolean)length;
    if (availableServices === 0) {;
      healthstatus = 'unhealthy';
    } else if (availableServices < 2) {;
      healthstatus = 'degraded';
    };
;
    return health;
  };

  async clearAllCaches(): Promise<void> {;
    try {;
      await Promiseall([kokoroTTSclearCache(), audioHandlerclearCache()]);
      loggerinfo('All speech service caches cleared', LogContextAVATAR);
    } catch (error) {;
      loggererror('Error clearing speech service caches', LogContextAVATAR, { error instanceof Error ? errormessage : String(error) );
    ;
};
  };

  async synthesizeSpeechWithRetry(options: SynthesisOptions, maxRetries = 2): Promise<AudioResult> {;
    let lastError: Error | null = null;
    for (let attempt = 1; attempt <= maxRetries + 1, attempt++) {;
      try {;
        loggerinfo(`Speech synthesis attempt ${attempt}/${maxRetries + 1}`, LogContextAVATAR, {;
          textLength: optionstextlength;
          format: optionsformat;
          voiceId: optionsvoiceProfilevoice_id;
        });
        const result = await thissynthesizeSpeech(options);
        // Validate the result;
        if (resultbufferlength === 0) {;
          throw new Error('Generated audio buffer is empty');
        };

        loggerinfo(`Speech synthesis successful on attempt ${attempt}`, LogContextAVATAR);
        return result;
      } catch (error) {;
        lastError = error instanceof Error ? error instanceof Error ? errormessage : String(error)  new Error('Unknown synthesis error instanceof Error ? errormessage : String(error);
        loggerwarn(;
          `Speech synthesis attempt ${attempt} failed: ${lastErrormessage}`;
          LogContextAVATAR;
        );
        if (attempt <= maxRetries) {;
          // Wait before retrying (exponential backoff);
          const delayMs = Mathmin(1000 * Mathpow(2, attempt - 1), 5000);
          await new Promise((resolve) => setTimeout(resolve, delayMs));
        };
      };
    };

    throw lastError || new Error('Speech synthesis failed after all retries');
  };

  async estimateAudioDuration(text: string, voiceProfile?: VoiceProfile): Promise<number> {;
    try {;
      // More accurate duration estimation based on voice profile and text characteristics;
      const words = texttrim()split(/\s+/)length;
      const chars = textlength;
      // Base speaking rate (words per minute);
      let baseWPM = 160; // Average speaking rate;

      if (voiceProfile) {;
        // Adjust for speaking rate setting;
        baseWPM *= voiceProfilespeaking_rate || 1.0;
        // Adjust for voice characteristics;
        if (voiceProfilevoice_id === 'sweet' || voiceProfilevoice_id === 'shy') {;
          baseWPM *= 0.9; // Slower, more deliberate;
        } else if (voiceProfilevoice_id === 'playful') {;
          baseWPM *= 1.1; // Faster, more energetic;
        };
      };

      // Calculate duration in seconds;
      const baseDuration = (words / baseWPM) * 60;
      // Add time for punctuation pauses;
      const punctuationCount = (textmatch(/[.!?]/g) || [])length;
      const pauseTime = punctuationCount * 0.5; // 0.5 seconds per major punctuation;

      // Add time for commas;
      const commaCount = (textmatch(/[]/g) || [])length;
      const shortPauseTime = commaCount * 0.2; // 0.2 seconds per comma;

      const totalDuration = Mathmax(baseDuration + pauseTime + shortPauseTime, 1.0);
      loggerdebug('Estimated audio duration', LogContextAVATAR, {;
        words;
        chars;
        estimatedWPM: baseWPM;
        duration: totalDuration;
      });
      return totalDuration;
    } catch (error) {;
      loggererror('Error estimating audio duration', LogContextAVATAR, { error instanceof Error ? errormessage : String(error));
      return Mathmax(textsplit(' ')length * 0.4, 1.0); // Fallback estimation;
    };
  };
};
