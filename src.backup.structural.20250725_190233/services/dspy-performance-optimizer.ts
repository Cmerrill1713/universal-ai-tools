/**;
 * DSPy Performance Optimizer;
 *;
 * Enhances DSPy orchestration performance through:;
 * - Intelligent caching of DSPy responses;
 * - Performance monitoring and optimization;
 * - Adaptive model selection;
 * - Resource allocation optimization;
 */;

import { EventEmitter } from 'events';
import { logger } from '../utils/logger';
import { memoryManager } from './memory-manager';
import { dspyService } from './dspy-service';
import { performance } from 'perf_hooks';
export interface DSPyPerformanceMetrics {;
  totalRequests: number;
  successfulRequests: number;
  averageLatency: number;
  cacheHitRate: number;
  modelPerformance: Map<string, ModelMetrics>;
  optimizationScore: number;
  lastOptimized: Date;
;
};

export interface ModelMetrics {;
  name: string;
  totalRequests: number;
  successfulRequests: number;
  averageLatency: number;
  averageConfidence: number;
  memoryUsage: number;
  complexity: number;
;
};

export interface OptimizationConfig {;
  enableCaching: boolean;
  enableModelSelection: boolean;
  enableResourceOptimization: boolean;
  cacheSize: number;
  optimizationInterval: number;
  performanceThreshold: number;
;
};

export class DSPyPerformanceOptimizer extends EventEmitter {;
  private static instance: DSPyPerformanceOptimizer;
  private config: OptimizationConfig;
  private metrics: DSPyPerformanceMetrics;
  private responseCache = new Map<string, any>();
  private modelSelectionCache = new Map<string, string>();
  private optimizationTimer?: NodeJSTimeout;
  private isOptimizing = false;
  private constructor(config: Partial<OptimizationConfig> = {}) {;
    super();
    thisconfig = {;
      enableCaching: true;
      enableModelSelection: true;
      enableResourceOptimization: true;
      cacheSize: 1000;
      optimizationInterval: 300000, // 5 minutes;
      performanceThreshold: 0.8;
      ..config;
    ;
};
    thismetrics = {;
      totalRequests: 0;
      successfulRequests: 0;
      averageLatency: 0;
      cacheHitRate: 0;
      modelPerformance: new Map();
      optimizationScore: 1.0;
      lastOptimized: new Date();
    ;
};
    thisinitialize();
  };

  public static getInstance(config?: Partial<OptimizationConfig>): DSPyPerformanceOptimizer {;
    if (!DSPyPerformanceOptimizerinstance) {;
      DSPyPerformanceOptimizerinstance = new DSPyPerformanceOptimizer(config);
    };
    return DSPyPerformanceOptimizerinstance;
  };

  private initialize(): void {;
    // Register AI-specific caches in memory manager;
    memoryManageroptimizeForAI();
    // Start periodic optimization;
    if (thisconfigoptimizationInterval > 0) {;
      thisoptimizationTimer = setInterval(() => {;
        thisperformOptimization();
      }, thisconfigoptimizationInterval);
    };

    loggerinfo('üöÄ DSPy Performance Optimizer initialized');
  };

  /**;
   * Optimize DSPy requestwith caching and performance monitoring;
   */;
  async optimizeRequest(operation: string, params: any): Promise<unknown> {;
    const startTime = performancenow();
    const cacheKey = thisgenerateCacheKey(operation, params);
    thismetricstotalRequests++;
    // Check cache first;
    if (thisconfigenableCaching) {;
      const cached = thisgetCachedResponse(cacheKey);
      if (cached) {;
        thisupdateCacheHitRate(true);
        loggerdebug(`üéØ Cache hit for DSPy operation: ${operation}`);
        return cached;
      };
    };

    // Select optimal model if enabled;
    let optimizedParams = params;
    if (thisconfigenableModelSelection) {;
      optimizedParams = await thisoptimizeModelSelection(operation, params);
    };

    try {;
      // Execute DSPy request;
      const result = await dspyServicerequestoperation, optimizedParams);
      const latency = performancenow() - startTime;
      // Update metrics;
      thisupdateMetrics(operation, latency, resultsuccess, optimizedParamsmodel);
      // Cache successful responses;
      if (thisconfigenableCaching && resultsuccess) {;
        thiscacheResponse(cacheKey, result);
      };

      // Update cache hit rate for miss;
      thisupdateCacheHitRate(false);
      thismetricssuccessfulRequests++;
      loggerdebug(`‚úÖ DSPy requestcompleted: ${operation} (${latencytoFixed(2)}ms)`);
      thisemit('request_completed', { operation, latency, success: resultsuccess });
      return result;
    } catch (error) {;
      const latency = performancenow() - startTime;
      thisupdateMetrics(operation, latency, false, optimizedParamsmodel);
      loggererror`‚ùå DSPy requestfailed: ${operation}`, error instanceof Error ? errormessage : String(error);
      thisemit('request_failed', { operation, latency, error instanceof Error ? errormessage : String(error));
      throw error instanceof Error ? errormessage : String(error);
    };
  };

  /**;
   * Generate cache key for DSPy requests;
   */;
  private generateCacheKey(operation: string, params: any): string {;
    const paramsHash = Bufferfrom(JSONstringify(params))toString('base64')substring(0, 32);
    return `dspy:${operation}:${paramsHash}`;
  };

  /**;
   * Get cached response;
   */;
  private getCachedResponse(key: string): any | null {;
    if (thisresponseCachehas(key)) {;
      const cached = thisresponseCacheget(key);
      // Check if cache entry is still valid (1 hour TTL);
      if (Datenow() - cachedtimestamp < 3600000) {;
        return cacheddata;
      } else {;
        thisresponseCachedelete(key);
      };
    };
    return null;
  };

  /**;
   * Cache DSPy response;
   */;
  private cacheResponse(key: string, data: any): void {;
    // Implement LRU cache behavior;
    if (thisresponseCachesize >= thisconfigcacheSize) {;
      const firstKey = thisresponseCachekeys()next()value;
      if (firstKey !== undefined) {;
        thisresponseCachedelete(firstKey);
      };
    };

    thisresponseCacheset(key, {;
      data;
      timestamp: Datenow();
    });
    // Also store in memory manager;
    memoryManageraddCacheEntry(;
      'dspy_outputs';
      key;
      JSONstringify(data)length;
      3 // Medium priority;
    );
  };

  /**;
   * Optimize model selection based on historical performance;
   */;
  private async optimizeModelSelection(operation: string, params: any): Promise<unknown> {;
    if (!paramsmodel) {;
      // Select best performing model for this operation;
      const bestModel = thisselectOptimalModel(operation);
      if (bestModel) {;
        paramsmodel = bestModel;
        loggerdebug(`üéØ Selected optimal model: ${bestModel} for ${operation}`);
      };
    };
    return params;
  };

  /**;
   * Select optimal model based on performance metrics;
   */;
  private selectOptimalModel(operation: string): string | null {;
    let bestModel: string | null = null;
    let bestScore = 0;
    thismetricsmodelPerformanceforEach((metrics, modelName) => {;
      // Calculate performance score;
      const successRate = metricssuccessfulRequests / metricstotalRequests;
      const latencyScore = Mathmax(0, 1 - metricsaverageLatency / 10000); // Normalize latency;
      const confidenceScore = metricsaverageConfidence;
      const performanceScore = successRate * 0.4 + latencyScore * 0.3 + confidenceScore * 0.3;
      if (performanceScore > bestScore) {;
        bestScore = performanceScore;
        bestModel = modelName;
      };
    });
    return bestModel;
  };

  /**;
   * Update performance metrics;
   */;
  private updateMetrics(;
    operation: string;
    latency: number;
    success: boolean;
    model?: string;
  ): void {;
    // Update overall metrics;
    thismetricsaverageLatency =;
      (thismetricsaverageLatency * (thismetricstotalRequests - 1) + latency) /;
      thismetricstotalRequests;
    // Update model-specific metrics;
    if (model) {;
      if (!thismetricsmodelPerformancehas(model)) {;
        thismetricsmodelPerformanceset(model, {;
          name: model;
          totalRequests: 0;
          successfulRequests: 0;
          averageLatency: 0;
          averageConfidence: 0;
          memoryUsage: 0;
          complexity: 0;
        });
      };

      const modelMetrics = thismetricsmodelPerformanceget(model)!;
      modelMetricstotalRequests++;
      if (success) modelMetricssuccessfulRequests++;
      modelMetricsaverageLatency =;
        (modelMetricsaverageLatency * (modelMetricstotalRequests - 1) + latency) /;
        modelMetricstotalRequests;
    };

    // Update optimization score;
    thisupdateOptimizationScore();
  };

  /**;
   * Update cache hit rate;
   */;
  private updateCacheHitRate(isHit: boolean): void {;
    const hitWeight = isHit ? 1 : 0;
    thismetricscacheHitRate =;
      (thismetricscacheHitRate * (thismetricstotalRequests - 1) + hitWeight) /;
      thismetricstotalRequests;
  };

  /**;
   * Calculate and update optimization score;
   */;
  private updateOptimizationScore(): void {;
    const successRate = thismetricssuccessfulRequests / thismetricstotalRequests;
    const latencyScore = Mathmax(0, 1 - thismetricsaverageLatency / 5000); // Target 5s max latency;
    const cacheEfficiency = thismetricscacheHitRate;
    thismetricsoptimizationScore = successRate * 0.4 + latencyScore * 0.3 + cacheEfficiency * 0.3;
  };

  /**;
   * Perform optimization cycle;
   */;
  private async performOptimization(): Promise<void> {;
    if (thisisOptimizing) return;
    thisisOptimizing = true;
    loggerinfo('üîÑ Starting DSPy performance optimization cycle...');
    try {;
      // Clear old cache entries;
      thiscleanupCache();
      // Optimize model selection cache;
      thisoptimizeModelSelectionCache();
      // Update optimization timestamp;
      thismetricslastOptimized = new Date();
      // Emit optimization event;
      thisemit('optimization_completed', {;
        score: thismetricsoptimizationScore;
        cacheHitRate: thismetricscacheHitRate;
        averageLatency: thismetricsaverageLatency;
      });
      loggerinfo(`‚úÖ Optimization completed. Score: ${thismetricsoptimizationScoretoFixed(3)}`);
    } catch (error) {;
      loggererror('‚ùå Optimization cycle failed:', error instanceof Error ? errormessage : String(error);
    } finally {;
      thisisOptimizing = false;
    };
  };

  /**;
   * Clean up old cache entries;
   */;
  private cleanupCache(): void {;
    const now = Datenow();
    const entriesRemoved: string[] = [];
    thisresponseCacheforEach((value, key) => {;
      if (now - valuetimestamp > 3600000) {;
        // 1 hour TTL;
        thisresponseCachedelete(key);
        entriesRemovedpush(key);
      };
    });
    if (entriesRemovedlength > 0) {;
      loggerdebug(`üßπ Cleaned up ${entriesRemovedlength} expired cache entries`);
    };
  };

  /**;
   * Optimize model selection cache;
   */;
  private optimizeModelSelectionCache(): void {;
    // Clear underperforming model selections;
    thismodelSelectionCacheclear();
    // Rebuild with current best performers;
    thismetricsmodelPerformanceforEach((metrics, modelName) => {;
      const performanceScore = metricssuccessfulRequests / metricstotalRequests;
      if (performanceScore >= thisconfigperformanceThreshold) {;
        thismodelSelectionCacheset(modelName, modelName);
      };
    });
  };

  /**;
   * Get current performance metrics;
   */;
  getMetrics(): DSPyPerformanceMetrics {;
    return { ..thismetrics };
  };

  /**;
   * Get optimization recommendations;
   */;
  getOptimizationRecommendations(): string[] {;
    const recommendations: string[] = [];
    if (thismetricscacheHitRate < 0.3) {;
      recommendationspush('Consider increasing cache size for better performance');
    };

    if (thismetricsaverageLatency > 5000) {;
      recommendationspush('High latency detected - consider model optimization');
    };

    if (thismetricsoptimizationScore < 0.7) {;
      recommendationspush('Overall performance below threshold - review configuration');
    };

    const bestModel = thisselectOptimalModel('general');
    if (bestModel) {;
      recommendationspush(`Best performing model: ${bestModel}`);
    };

    return recommendations;
  };

  /**;
   * Force optimization cycle;
   */;
  async forceOptimization(): Promise<void> {;
    await thisperformOptimization();
  ;
};

  /**;
   * Clear all caches;
   */;
  clearCaches(): void {;
    thisresponseCacheclear();
    thismodelSelectionCacheclear();
    loggerinfo('üßπ All DSPy caches cleared');
  ;
};

  /**;
   * Reset metrics;
   */;
  resetMetrics(): void {;
    thismetrics = {;
      totalRequests: 0;
      successfulRequests: 0;
      averageLatency: 0;
      cacheHitRate: 0;
      modelPerformance: new Map();
      optimizationScore: 1.0;
      lastOptimized: new Date();
    ;
};
    loggerinfo('üìä Performance metrics reset');
  };

  /**;
   * Shutdown optimizer;
   */;
  shutdown(): void {;
    if (thisoptimizationTimer) {;
      clearInterval(thisoptimizationTimer);
    };
    thisclearCaches();
    thisremoveAllListeners();
    loggerinfo('üî• DSPy Performance Optimizer shutdown complete');
  };
};

// Export singleton instance;
export const dspyOptimizer = DSPyPerformanceOptimizergetInstance();