/* eslint-disable no-undef */;
import { createClient } from '@supabase/supabase-js';
import { config } from '../config/environment';
interface OllamaRequest {;
  prompt: string;
  model?: string;
  temperature?: number;
  max_tokens?: number;
  stream?: boolean;
  system?: string;
};

interface OllamaResponse {;
  response: string;
  model: string;
  usage: {;
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
};
};

interface StreamChunk {;
  contentstring;
  done: boolean;
};

export class OllamaSupabaseBridge {;
  private supabase: any;
  constructor() {;
    thissupabase = createClient(;);
      configdatabasesupabaseUrl;
      configdatabasesupabaseAnonKey || '';
    )};

  /**;
   * Send a prompt to Ollama via Supabase Edge Function;
   */;
  async generate(requestOllamaRequest): Promise<OllamaResponse> {;
    try {;
      const { data, error } = await thissupabasefunctionsinvoke('ollama-assistant', {;
        body: {;
          prompt: requestprompt;
          model: requestmodel || 'llama3.2:3b';
          temperature: requesttemperature || 0.7;
          max_tokens: requestmax_tokens || 1000;
          stream: false;
          system: requestsystem || 'You are a helpful AI assistant.'}});
      if (error instanceof Error ? errormessage : String(error){;
        throw new Error(`Supabase function error instanceof Error ? errormessage : String(error) ${errormessage}`);
      };

      return data as OllamaResponse;
    } catch (error) {;
      consoleerror instanceof Error ? errormessage : String(error) Error calling Ollama via Supabase:', error instanceof Error ? errormessage : String(error);
      throw error instanceof Error ? errormessage : String(error)};
  };

  /**;
   * Stream a response from Ollama via Supabase Edge Function;
   */;
  async *generateStream(requestOllamaRequest): AsyncGenerator<string> {;
    try {;
      const response = await fetch(`${configdatabasesupabaseUrl}/functions/v1/ollama-assistant`, {;
        method: 'POST';
        headers: {;
          'Content-Type': 'application/json';
          Authorization: `Bearer ${configdatabasesupabaseAnonKey}`;
          apikey: configdatabasesupabaseAnonKey || ''};
        body: JSONstringify({;
          prompt: requestprompt;
          model: requestmodel || 'llama3.2:3b';
          temperature: requesttemperature || 0.7;
          max_tokens: requestmax_tokens || 1000;
          stream: true;
          system: requestsystem || 'You are a helpful AI assistant.'})});
      if (!responseok) {;
        throw new Error(`HTTP error instanceof Error ? errormessage : String(error) status: ${responsestatus}`);
      };

      const reader = responsebody?getReader();
      if (!reader) {;
        throw new Error('No response body')};

      const decoder = new TextDecoder();
      let buffer = '';
      while (true) {;
        const { done, value } = await readerread();
        if (done) break;
        buffer += decoderdecode(value, { stream: true });
        const lines = buffersplit('\n');
        // Process all complete lines;
        for (let i = 0; i < lineslength - 1; i++) {;
          const line = lines[i]trim();
          if (linestartsWith('data: ')) {;
            try {;
              const data = JSONparse(lineslice(6)) as StreamChunk;
              if (!datadone && datacontent{;
                yield datacontent};
            } catch (e) {;
              // Skip invalid JSON;
            };
          };
        };

        // Keep the last incomplete line in the buffer;
        buffer = lines[lineslength - 1];
      };
    } catch (error) {;
      consoleerror instanceof Error ? errormessage : String(error) Error streaming from Ollama via Supabase:', error instanceof Error ? errormessage : String(error);
      throw error instanceof Error ? errormessage : String(error)};
  };

  /**;
   * Get available models from Ollama;
   */;
  async listModels(): Promise<string[]> {;
    // For now, return a static list of commonly used models;
    // In a real implementation, you might want to create another Edge Function;
    // that queries the Ollama API for available models;
    return [;
      'llama3.2: 3b';
      'llama3.2: 1b';
      'mistral: 7b';
      'gemma: 2b';
      'phi: 2.7b-chat-v2-q4_0';
      'qwen: 0.5b'];
};

  /**;
   * Health check for the Ollama service;
   */;
  async healthCheck(): Promise<boolean> {;
    try {;
      const response = await thisgenerate({;
        prompt: 'Hello';
        max_tokens: 10});
      return !!responseresponse;
    } catch (error) {;
      consoleerror instanceof Error ? errormessage : String(error) Ollama health check failed:', error instanceof Error ? errormessage : String(error);
      return false};
  };
};

// Export a singleton instance;
export const ollamaSupabase = new OllamaSupabaseBridge();