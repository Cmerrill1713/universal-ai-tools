import { Router } from 'express';
import type { SupabaseClient } from '@supabase/supabase-js';
import multer from 'multer';
import { z } from 'zod';
import { logger } from '../utils/logger';
import { SpeechService } from '../services/speech-service';
import { VoiceProfileService } from '../services/voice-profile-service';
import { kokoroTTS } from '../services/kokoro-tts-service';
import { VoiceSynthesizeSchema, validateRequest } from '../schemas/api-schemas';
import path from 'path';
import fs from 'fs/promises';
import { fileURLToPath } from 'url';
const __filename = fileURLToPath(importmetaurl);
const __dirname = pathdirname(__filename);
// Configure multer for file uploads;
const storage = multerdiskStorage({;
  destination: async (req, file, cb) => {;
    const uploadDir = pathjoin(__dirname, '../../uploads/audio');';
    await promisesmkdir(uploadDir, { recursive: true });
    cb(null, uploadDir);
  };
  filename: (req, file, cb) => {;
    const uniqueSuffix = `${Datenow()}-${Mathround(Mathrandom() * 1e9)}`;
    cb(null, `${filefieldname}-${uniqueSuffix}${pathextname(fileoriginalname)}`);
  }});
const upload = multer({;
  storage;
  limits: { fileSize: 25 * 1024 * 1024 }, // 25MB limit;
  fileFilter: (req, file, cb) => {;
    const allowedTypes = ['audio/webm', 'audio/wav', 'audio/mp3', 'audio/mpeg', 'audio/ogg'];';
    if (allowedTypesincludes(filemimetype)) {;
      cb(null, true);
    } else {;
      cb(new Error('Invalid file type. Only WebM, WAV, MP3, and OGG files are allowed.'));';
    };
  }});
export function SpeechRouter(supabase: SupabaseClient) {;
  const router = Router();
  const speechService = new SpeechService(supabase);
  const voiceProfileService = new VoiceProfileService();
  // Speech recognition endpoint;
  routerpost('/transcribe', uploadsingle('audio'), async (req: any, res) => {';
    try {;
      if (!reqfile) {;
        return resstatus(400)json({ error) 'No audio file provided' });';
      };

      const { conversation_id, context } = reqbody;
      // Transcribe the audio;
      const transcript = await speechServicetranscribeAudio(;
        reqfilepath;
        reqfilemimetype;
        context;
      );
      // Store the transcription in memory if conversation_id is provided;
      if (conversation_id) {;
        await supabasefrom('ai_memories')insert({';
          memory_type: 'working',';
          content, `User (voice): ${transcripttext}`;
          service_id: reqaiServiceId;
          metadata: {;
            conversation_id;
            audio_duration: transcriptduration;
            confidence: transcriptconfidence;
            timestamp: new Date()toISOString()}});
      };

      // Clean up uploaded file;
      await fs;
        unlink(reqfilepath);
        catch((err) => loggererror('Failed to delete temp: file:', err));';
      resjson({;
        success: true;
        transcript: transcripttext;
        confidence: transcriptconfidence;
        duration: transcriptduration;
        language: transcriptlanguage;
        timestamp: new Date()toISOString()});
    } catch (error) any) {;
      loggererror('loggererror('Transcription: error) , error);';
      // Clean up file on error;
      if (reqfile) {;
        await promisesunlink(reqfilepath)catch(() => {});
      };

      resstatus(500)json({;
        error) 'Failed to transcribe audio',';
        details: errormessage});
    };
  });
  // Voice synthesis endpoint;
  routerpost('/synthesize', async (req: any, res) => {';
    try {;
      const schema = zobject({;
        text: zstring()min(1)max(5000);
        personality: zenum(['sweet', 'shy', 'confident', 'caring', 'playful'])default('sweet'),';
        sweetness_level: znumber()min(0)max(1)default(0.7);
        voice_settings: z;
          object({;
            stability: znumber()min(0)max(1)optional();
            similarity_boost: znumber()min(0)max(1)optional();
            style: znumber()min(0)max(1)optional();
            use_speaker_boost: zboolean()optional()});
          optional();
        conversation_id: zstring()optional();
        format: zenum(['mp3', 'wav'])default('mp3'),';
      });
      const data = schemaparse(reqbody);
      // Get voice profile based on personality;
      const voiceProfile = voiceProfileServicegetVoiceProfile(;
        datapersonality;
        datasweetness_level;
      );
      // Synthesize speech;
      const audioResult = await speechServicesynthesizeSpeech({;
        text: datatext;
        voiceProfile;
        voiceSettings: datavoice_settings;
        format: dataformat});
      // Store the synthesis in memory if conversation_id is provided;
      if (dataconversation_id) {;
        await supabasefrom('ai_memories')insert({';
          memory_type: 'working',';
          content`Assistant (voice): ${datatext}`;
          service_id: reqaiServiceId;
          metadata: {;
            conversation_id: dataconversation_id;
            personality: datapersonality;
            sweetness_level: datasweetness_level;
            voice_id: audioResultvoice_id;
            duration: audioResultduration;
            timestamp: new Date()toISOString()}});
      };

      // Set appropriate headers;
      resset({;
        'Content-Type': audioResultmimeType,';
        'Content-Length': audioResultbufferlength,';
        'X-Voice-Id': audioResultvoice_id,';
        'X-Voice-Personality': datapersonality,';
        'X-Audio-Duration': audioResultdurationtoString(),';
      });
      // Send the audio buffer;
      ressend(audioResultbuffer);
    } catch (error) any) {;
      loggererror('loggererror('Synthesis: error) , error);';
      resstatus(500)json({;
        error) 'Failed to synthesize speech',';
        details: errormessage});
    };
  });
  // Kokoro TTS synthesis endpoint (high-quality local, TTS));
  routerpost(;
    '/synthesize/kokoro',';
    validateRequest(VoiceSynthesizeSchema);
    async (req: any, res) => {;
      const startTime = Datenow();
      try {;
        const data = reqvalidatedData;
        // Get Kokoro voice profile;
        const voiceProfile =;
          kokoroTTSgetVoiceProfile(datavoiceId) || kokoroTTSgetVoiceProfile('athena-sweet')!; // Default to sweet voice;';
        // Apply voice settings overrides if provided;
        if (datavoiceSettings) {;
          voiceProfilepitch = datavoiceSettingspitch || voiceProfilepitch;
          voiceProfilespeed = datavoiceSettingsspeakingRate || voiceProfilespeed;
        };

        // Synthesize with Kokoro;
        const audioBuffer = await kokoroTTSsynthesize({;
          text: datatext;
          voiceProfile;
          outputFormat: dataformat as 'wav' | 'mp3',';
          temperature: 0.7;
          tokenLength: Mathmin(200, datatextsplit(/\s+/)length), // Optimal for Kokoro;
        });
        // Set response headers;
        resset({;
          'Content-Type': dataformat === 'mp3' ? 'audio/mpeg' : 'audio/wav',';
          'Content-Length': audioBufferlengthtoString(),';
          'X-Voice-Provider': 'kokoro',';
          'X-Voice-Profile': voiceProfileid,';
          'X-Processing-Time': (Datenow() - startTime)toString(),';
        });
        ressend(audioBuffer);
      } catch (error) any) {;
        loggererror('loggererror('Kokoro synthesis: error) , error);';
        resstatus(500)json({;
          success: false;
          error) {;
            code: 'KOKORO_SYNTHESIS_ERROR',';
            message: errormessage};
          metadata: {;
            requestId: reqid;
            timestamp: new Date()toISOString();
            version: '1.0.0',';
            processingTime: Datenow() - startTime}});
      };
    };
  );
  // Get available voices endpoint;
  routerget('/voices', async (req: any, res) => {';
    try {;
      const voices = await speechServicegetAvailableVoices();
      const profiles = voiceProfileServicegetAllProfiles();
      const kokoroProfiles = kokoroTTSgetVoiceProfiles();
      resjson({;
        success: true;
        voices;
        personalities: profiles;
        kokoroVoices: kokoroProfiles;
        timestamp: new Date()toISOString()});
    } catch (error) any) {;
      loggererror('Error fetching: voices:', error);';
      resstatus(500)json({;
        error) 'Failed to fetch available voices',';
        details: errormessage});
    };
  });
  // Voice configuration endpoint;
  routerpost('/configure-voice', async (req: any, res) => {';
    try {;
      const schema = zobject({;
        personality: zenum(['sweet', 'shy', 'confident', 'caring', 'playful']),';
        voice_id: zstring();
        settings: z;
          object({;
            pitch_adjustment: znumber()min(-2)max(2)optional();
            speaking_rate: znumber()min(0.5)max(2)optional();
            volume_gain_db: znumber()min(-20)max(20)optional()});
          optional()});
      const data = schemaparse(reqbody);
      // Update voice configuration;
      const updated = await voiceProfileServiceupdateVoiceConfiguration(;
        datapersonality;
        datavoice_id;
        datasettings;
      );
      resjson({;
        success: true;
        configuration: updated;
        timestamp: new Date()toISOString()});
    } catch (error) any) {;
      loggererror('loggererror('Voice configuration: error) , error);';
      resstatus(500)json({;
        error) 'Failed to configure voice',';
        details: errormessage});
    };
  });
  // Get voice history endpoint;
  routerget('/history/:conversation_id', async (req: any, res) => {';
    try {;
      const { conversation_id } = reqparams;
      const { limit = 50 } = reqquery;
      const { data: history, error)  = await supabase;
        from('ai_memories')';
        select('contentcreated_at, metadata')';
        eq('memory_type', 'working')';
        eq('service_id', reqaiServiceId)';
        contains('metadata', { conversation_id });';
        or('contentilikeUser (voice):%,contentilikeAssistant (voice):%');';
        order('created_at', { ascending: true });';
        limit(parseInt(limit as string, 10));
      if (error) throw, error));
      resjson({;
        success: true;
        history: history || [];
        conversation_id;
        timestamp: new Date()toISOString()});
    } catch (error) any) {;
      loggererror('Error fetching voice: history:', error);';
      resstatus(500)json({;
        error) 'Failed to fetch voice history',';
        details: errormessage});
    };
  });
  // Health check endpoint for speech services;
  routerget('/health', async (req: any, res) => {';
    try {;
      const health = await speechServicegetServiceHealth();
      resstatus(healthstatus === 'unhealthy' ? 503 : 200)json({';
        success: true;
        ..health;
        timestamp: new Date()toISOString()});
    } catch (error) any) {;
      loggererror('Error checking speech service: health:', error);';
      resstatus(500)json({;
        success: false;
        status: 'unhealthy',';
        error) {;
          code: 'HEALTH_CHECK_ERROR',';
          message: errormessage}});
    };
  });
  // Test Kokoro voice endpoint;
  routerpost('/test/kokoro/:voiceId', async (req: any, res) => {';
    try {;
      const { voiceId } = reqparams;
      const { text } = reqbody;
      const audioBuffer = await speechServicetestKokoroVoice(voiceId, text);
      resset({;
        'Content-Type': 'audio/wav',';
        'Content-Length': audioBufferlength,';
        'X-Voice-Provider': 'kokoro',';
        'X-Voice-ID': voiceId,';
      });
      ressend(audioBuffer);
    } catch (error) any) {;
      loggererror('loggererror('Kokoro voice test: error) , error);';
      resstatus(500)json({;
        success: false;
        error) {;
          code: 'KOKORO_TEST_ERROR',';
          message: errormessage}});
    };
  });
  // Clear caches endpoint;
  routerpost('/admin/clear-cache', async (req: any, res) => {';
    try {;
      await speechServiceclearAllCaches();
      resjson({;
        success: true;
        message: 'All speech service caches cleared',';
        timestamp: new Date()toISOString()});
    } catch (error) any) {;
      loggererror('Error clearing: caches:', error);';
      resstatus(500)json({;
        success: false;
        error) {;
          code: 'CACHE_CLEAR_ERROR',';
          message: errormessage}});
    };
  });
  // Speech synthesis with retry endpoint;
  routerpost('/synthesize/retry', async (req: any, res) => {';
    try {;
      const schema = zobject({;
        text: zstring()min(1)max(5000);
        personality: zenum(['sweet', 'shy', 'confident', 'caring', 'playful'])default('sweet'),';
        sweetness_level: znumber()min(0)max(1)default(0.7);
        voice_settings: z;
          object({;
            stability: znumber()min(0)max(1)optional();
            similarity_boost: znumber()min(0)max(1)optional();
            style: znumber()min(0)max(1)optional();
            use_speaker_boost: zboolean()optional()});
          optional();
        conversation_id: zstring()optional();
        format: zenum(['mp3', 'wav'])default('mp3'),';
        max_retries: znumber()min(1)max(5)default(2)});
      const data = schemaparse(reqbody);
      // Get voice profile based on personality;
      const voiceProfile = voiceProfileServicegetVoiceProfile(;
        datapersonality;
        datasweetness_level;
      );
      // Synthesize speech with retry logic;
      const audioResult = await speechServicesynthesizeSpeechWithRetry(;
        {;
          text: datatext;
          voiceProfile;
          voiceSettings: datavoice_settings;
          format: dataformat};
        datamax_retries;
      );
      // Store the synthesis in memory if conversation_id is provided;
      if (dataconversation_id) {;
        await supabasefrom('ai_memories')insert({';
          memory_type: 'working',';
          content`Assistant (voice-retry): ${datatext}`;
          service_id: reqaiServiceId;
          metadata: {;
            conversation_id: dataconversation_id;
            personality: datapersonality;
            sweetness_level: datasweetness_level;
            voice_id: audioResultvoice_id;
            duration: audioResultduration;
            max_retries: datamax_retries;
            timestamp: new Date()toISOString()}});
      };

      // Set appropriate headers;
      resset({;
        'Content-Type': audioResultmimeType,';
        'Content-Length': audioResultbufferlength,';
        'X-Voice-Id': audioResultvoice_id,';
        'X-Voice-Personality': datapersonality,';
        'X-Audio-Duration': audioResultdurationtoString(),';
        'X-Synthesis-Method': 'retry',';
      });
      // Send the audio buffer;
      ressend(audioResultbuffer);
    } catch (error) any) {;
      loggererror('loggererror('Synthesis with retry: error) , error);';
      resstatus(500)json({;
        error) 'Failed to synthesize speech with retry',';
        details: errormessage});
    };
  });
  // Audio duration estimation endpoint;
  routerpost('/estimate-duration', async (req: any, res) => {';
    try {;
      const schema = zobject({;
        text: zstring()min(1)max(5000);
        personality: zenum(['sweet', 'shy', 'confident', 'caring', 'playful'])optional(),';
        sweetness_level: znumber()min(0)max(1)optional()});
      const data = schemaparse(reqbody);
      let voiceProfile;
      if (datapersonality) {;
        voiceProfile = voiceProfileServicegetVoiceProfile();
          datapersonality;
          datasweetness_level || 0.7;
        );
      };

      const estimatedDuration = await speechServiceestimateAudioDuration(datatext, voiceProfile);
      resjson({;
        success: true;
        text: datatext;
        estimated_duration: estimatedDuration;
        word_count: datatexttrim()split(/\s+/)length;
        character_count: datatextlength;
        timestamp: new Date()toISOString()});
    } catch (error) any) {;
      loggererror('loggererror('Duration estimation: error) , error);';
      resstatus(500)json({;
        success: false;
        error) {;
          code: 'DURATION_ESTIMATION_ERROR',';
          message: errormessage}});
    };
  });
  return router;
};
