version: '3.8'

name: universal-ai-tools-prod

services:
  # Main Universal AI Tools Service
  api:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    image: universal-ai-tools:latest
    container_name: universal-ai-tools-api
    restart: always
    ports:
      - '9998:9999'
    env_file:
      - .env.production
    environment:
      - NODE_ENV=production
      - PORT=9999
      - OLLAMA_URL=http://ollama:11434
      - REDIS_URL=redis://redis:6379
      - PROMETHEUS_URL=http://prometheus:9090
      - ENABLE_METAL_OPTIMIZATION=true
      - CONTAINER_NAME=universal-ai-tools-api
    volumes:
      - ./logs:/app/logs:rw
      - ./cache:/app/cache:rw
      - model_data:/app/models
    depends_on:
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    networks:
      - ai-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9999/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: universal-ai-tools-redis
    restart: always
    command: >
      redis-server
      --appendonly yes
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      ${REDIS_PASSWORD:+--requirepass ${REDIS_PASSWORD}}
    volumes:
      - redis_data:/data
    ports:
      - '127.0.0.1:6380:6379'
    networks:
      - ai-network
    healthcheck:
      test: ['CMD', 'redis-cli', '--raw', 'incr', 'ping']
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 2G

  # Ollama for Local LLM
  ollama:
    image: ollama/ollama:latest
    container_name: universal-ai-tools-ollama
    restart: always
    ports:
      - '127.0.0.1:11434:11434'
    volumes:
      - ollama_models:/root/.ollama
    environment:
      - OLLAMA_NUM_PARALLEL=4
      - OLLAMA_MAX_LOADED_MODELS=2
      - OLLAMA_KEEP_ALIVE=5m
    networks:
      - ai-network
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
    # Pre-pull models on startup
    entrypoint: >
      sh -c "
        ollama serve &
        sleep 5 &&
        ollama pull nomic-embed-text &&
        ollama pull llama3.2:3b &&
        wait
      "

  # Nginx Reverse Proxy with SSL
  nginx:
    image: nginx:alpine
    container_name: universal-ai-tools-nginx
    restart: always
    ports:
      - '80:80'
      - '443:443'
      - '127.0.0.1:8080:8080'  # Monitoring endpoint
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/html:/usr/share/nginx/html:ro
      - nginx_cache:/var/cache/nginx
      - nginx_logs:/var/log/nginx
    environment:
      - NGINX_WORKER_PROCESSES=auto
      - NGINX_WORKER_CONNECTIONS=1024
    depends_on:
      api:
        condition: service_healthy
    networks:
      - ai-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/nginx_status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: 'json-file'
      options:
        max-size: '5m'
        max-file: '3'

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: universal-ai-tools-prometheus
    restart: always
    ports:
      - '127.0.0.1:9090:9090'
    volumes:
      - ./monitoring/prometheus/prometheus.prod.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - ai-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: universal-ai-tools-grafana
    restart: always
    ports:
      - '127.0.0.1:3000:3000'
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    networks:
      - ai-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

volumes:
  model_data:
    driver: local
  ollama_models:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  nginx_cache:
    driver: local
  nginx_logs:
    driver: local

networks:
  ai-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.31.0.0/16
