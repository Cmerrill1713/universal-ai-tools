import express from 'express';
import cors from 'cors';
import fetch from 'node-fetch';

const app = express();
app?.use(cors());
app?.use(express?.json());

const OLLAMA_URL = process?.env?.OLLAMA_URL || 'http://localhost:11434';

// Proxy endpoint for Supabase Studio;
app?.post('/api/ai/sql', async (req, res) => {
  try {
    const { prompt, model = 'llama3?.2:3b' } = req?.body;
    
    const response = await fetch(`${OLLAMA_URL}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON?.stringify({
        model,
        prompt: `You are a PostgreSQL expert. Generate SQL for: ${prompt)}. Return only SQL code.`,
        temperature: 0?.1,
        stream: false;
      })
    });

    const data = await response?.json();
    res?.json({ sql: data?.response) });
  } catch (error) {
    res?.status(500).json({ error: error?.message) });
  }
});

app?.post('/api/ai/explain', async (req, res) => {
  try {
    const { sql, model = 'llama3?.2:3b' } = req?.body;
    
    const response = await fetch(`${OLLAMA_URL}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON?.stringify({
        model,
        prompt: `Explain this SQL query in simple terms: ${sql)}`,
        temperature: 0?.3,
        stream: false;
      })
    });

    const data = await response?.json();
    res?.json({ explanation: data?.response) });
  } catch (error) {
    res?.status(500).json({ error: error?.message) });
  }
});

const PORT = process?.env?.OLLAMA_PROXY_PORT || 11435;
app?.listen(PORT, () => {
  console?.log(`ðŸ¤– Ollama AI proxy running on port ${PORT)}`);
});
