version: '3.8'

services:
  # Core Infrastructure (Go Services)
  api-gateway:
    build:
      context: ./go-services/api-gateway
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - PORT=8080
      - NODE_ENV=production
    networks:
      - universal-ai-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  auth-service:
    build:
      context: ./go-services/auth-service
      dockerfile: Dockerfile
    ports:
      - "8015:8015"
    environment:
      - PORT=8015
    networks:
      - universal-ai-network
    depends_on:
      - redis
      - postgres
    restart: unless-stopped

  # High-Performance ML Services (Rust)
  ml-inference:
    build:
      context: ./rust-services/ml-inference-service
      dockerfile: Dockerfile
    ports:
      - "8084:8084"
    environment:
      - RUST_LOG=info
      - PORT=8084
    networks:
      - universal-ai-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  llm-router:
    build:
      context: ./crates/llm-router
      dockerfile: Dockerfile
    ports:
      - "3031:3031"
    environment:
      - RUST_LOG=info
      - PORT=3031
    networks:
      - universal-ai-network
    restart: unless-stopped

  parameter-analytics:
    build:
      context: ./rust-services/parameter-analytics-service
      dockerfile: Dockerfile
    ports:
      - "3032:3032"
    environment:
      - RUST_LOG=info
      - PORT=3032
    networks:
      - universal-ai-network
    depends_on:
      - redis
    restart: unless-stopped

  # Additional Go Services
  chat-service:
    build:
      context: ./go-services/chat-service
      dockerfile: Dockerfile
    ports:
      - "8016:8016"
    environment:
      - PORT=8016
    networks:
      - universal-ai-network
    depends_on:
      - postgres
    restart: unless-stopped

  memory-service:
    build:
      context: ./go-services/memory-service
      dockerfile: Dockerfile
    ports:
      - "8017:8017"
    environment:
      - PORT=8017
    networks:
      - universal-ai-network
    depends_on:
      - postgres
      - redis
    restart: unless-stopped

  websocket-hub:
    build:
      context: ./go-services/websocket-hub
      dockerfile: Dockerfile
    ports:
      - "8018:8018"
    environment:
      - PORT=8018
    networks:
      - universal-ai-network
    restart: unless-stopped

  # Infrastructure Services
  postgres:
    image: postgres:16-alpine
    environment:
      - POSTGRES_DB=universal_ai_tools
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init:/docker-entrypoint-initdb.d
    networks:
      - universal-ai-network
    ports:
      - "5432:5432"
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - universal-ai-network
    ports:
      - "6379:6379"
    restart: unless-stopped

  # Optional: Legacy TypeScript Bridge (minimal)
  legacy-bridge:
    build:
      context: .
      dockerfile: Dockerfile.legacy-bridge
    ports:
      - "9999:9999"
    environment:
      - NODE_ENV=production
      - PORT=9999
      - LEGACY_BRIDGE_PORT=9999
      - API_GATEWAY_URL=http://api-gateway:8081
    networks:
      - universal-ai-network
    depends_on:
      - api-gateway
    restart: unless-stopped
    profiles:
      - legacy  # Only start if --profile legacy is used

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - universal-ai-network
    restart: unless-stopped
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - universal-ai-network
    restart: unless-stopped
    profiles:
      - monitoring

networks:
  universal-ai-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  grafana_data: