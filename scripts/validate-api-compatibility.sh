#!/bin/bash

# API Compatibility Validation Script
# Ensures LFM2-MLX migration maintains API compatibility
# Created: 2025-08-22

set -euo pipefail

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
VALIDATION_DIR="/tmp/api-compatibility-validation"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
VALIDATION_LOG="$VALIDATION_DIR/api_validation_$TIMESTAMP.log"

# Service endpoints
GO_API_PORT=8080
RUST_LLM_ROUTER_PORT=8082
RUST_AI_CORE_PORT=8003
MLX_SERVICE_PORT=8004

echo -e "${BLUE}üîå API Compatibility Validation Suite${NC}"
echo "==============================================="
echo "Timestamp: $(date)"
echo "Validation Directory: $VALIDATION_DIR"
echo "Validation Log: $VALIDATION_LOG"
echo ""

mkdir -p "$VALIDATION_DIR"

# Initialize validation log
cat > "$VALIDATION_LOG" << EOF
API Compatibility Validation Results
Generated: $(date)
===============================================

Testing API compatibility between legacy LFM2 and new MLX service
Ensuring zero-breaking-change migration

EOF

# Validation tracking
TOTAL_VALIDATIONS=0
PASSED_VALIDATIONS=0
FAILED_VALIDATIONS=0

log_validation() {
    local status="$1"
    local test_name="$2"
    local details="$3"
    
    echo -e "[$status] $test_name: $details" | tee -a "$VALIDATION_LOG"
    ((TOTAL_VALIDATIONS++))
    
    if [[ "$status" == "PASS" ]]; then
        ((PASSED_VALIDATIONS++))
        echo -e "${GREEN}‚úÖ PASS${NC}: $test_name"
    elif [[ "$status" == "FAIL" ]]; then
        ((FAILED_VALIDATIONS++))
        echo -e "${RED}‚ùå FAIL${NC}: $test_name - $details"
    else
        echo -e "${YELLOW}‚ÑπÔ∏è  INFO${NC}: $test_name - $details"
    fi
}

# Test API endpoint structure compatibility
validate_endpoint_structure() {
    echo -e "\n${BLUE}üõ†Ô∏è  Validating API Endpoint Structure${NC}"
    echo "======================================"
    
    # Define expected endpoints for LFM2 service
    local endpoints=(
        "/health"
        "/api/models"
        "/api/chat/completions"
        "/api/circuit-breaker/status"
        "/metrics"
    )
    
    for endpoint in "${endpoints[@]}"; do
        local mlx_response=$(curl -s -o /dev/null -w "%{http_code}" "http://localhost:$MLX_SERVICE_PORT$endpoint" || echo "000")
        
        case $mlx_response in
            200|201|202)
                log_validation "PASS" "Endpoint Structure" "$endpoint returns HTTP $mlx_response"
                ;;
            404)
                log_validation "FAIL" "Endpoint Structure" "$endpoint not implemented (HTTP 404)"
                ;;
            500|502|503)
                log_validation "FAIL" "Endpoint Structure" "$endpoint returns server error (HTTP $mlx_response)"
                ;;
            000)
                log_validation "FAIL" "Endpoint Structure" "$endpoint connection failed"
                ;;
            *)
                log_validation "WARN" "Endpoint Structure" "$endpoint returns HTTP $mlx_response (unexpected)"
                ;;
        esac
    done
}

# Validate request/response schema compatibility
validate_chat_completions_schema() {
    echo -e "\n${BLUE}üìù Validating Chat Completions Schema${NC}"
    echo "======================================"
    
    # Test request schema compatibility
    local test_requests=(
        '{"model": "lfm2:1.2b", "messages": [{"role": "user", "content": "test"}]}'
        '{"model": "lfm2:1.2b", "messages": [{"role": "user", "content": "test"}], "max_tokens": 50}'
        '{"model": "lfm2:1.2b", "messages": [{"role": "user", "content": "test"}], "temperature": 0.7}'
        '{"model": "lfm2:1.2b", "messages": [{"role": "user", "content": "test"}], "max_tokens": 100, "temperature": 0.5, "top_p": 0.9}'
    )
    
    local schema_file="$VALIDATION_DIR/response_schemas_$TIMESTAMP.json"
    echo "[]" > "$schema_file"
    
    for i in "${!test_requests[@]}"; do
        local request="${test_requests[$i]}"
        local request_name="schema_test_$((i+1))"
        
        echo -e "\n${YELLOW}Testing request schema $((i+1))...${NC}"
        
        # Test MLX service
        local mlx_response=$(curl -s -X POST "http://localhost:$MLX_SERVICE_PORT/api/chat/completions" \
            -H "Content-Type: application/json" \
            -d "$request" \
            --max-time 30 || echo "ERROR")
        
        if [[ "$mlx_response" == *"ERROR"* ]]; then
            log_validation "FAIL" "MLX Schema Test $((i+1))" "Request failed"
            continue
        fi
        
        # Validate response structure
        local has_id=$(echo "$mlx_response" | jq -r '.id // "missing"')
        local has_object=$(echo "$mlx_response" | jq -r '.object // "missing"')
        local has_choices=$(echo "$mlx_response" | jq -r '.choices // "missing"')
        local has_usage=$(echo "$mlx_response" | jq -r '.usage // "missing"')
        
        # Save response schema
        local schema_data=$(jq -n \
            --arg request_id "$request_name" \
            --arg has_id "$has_id" \
            --arg has_object "$has_object" \
            --arg has_choices "$has_choices" \
            --arg has_usage "$has_usage" \
            --argjson response "$mlx_response" \
            '{
                request_id: $request_id,
                schema_validation: {
                    has_id: ($has_id != "missing"),
                    has_object: ($has_object != "missing"),
                    has_choices: ($has_choices != "missing"),
                    has_usage: ($has_usage != "missing")
                },
                response: $response
            }')
        
        jq ". += [$schema_data]" "$schema_file" > "${schema_file}.tmp" && mv "${schema_file}.tmp" "$schema_file"
        
        # Validate required fields
        if [[ "$has_id" != "missing" && "$has_object" != "missing" && "$has_choices" != "missing" ]]; then
            log_validation "PASS" "MLX Schema Test $((i+1))" "All required fields present"
        else
            log_validation "FAIL" "MLX Schema Test $((i+1))" "Missing required fields: id=$has_id, object=$has_object, choices=$has_choices"
        fi
    done
}

# Test backward compatibility with existing client code
validate_client_compatibility() {
    echo -e "\n${BLUE}üîó Validating Client Compatibility${NC}"
    echo "=================================="
    
    # Test compatibility with existing SwiftUI client patterns
    local swift_client_test='{"model": "lfm2:1.2b", "messages": [{"role": "user", "content": "Client compatibility test"}], "stream": false}'
    
    local response=$(curl -s -X POST "http://localhost:$MLX_SERVICE_PORT/api/chat/completions" \
        -H "Content-Type: application/json" \
        -H "User-Agent: Universal-AI-Tools-Swift/1.0" \
        -d "$swift_client_test" \
        --max-time 30 || echo "ERROR")
    
    if [[ "$response" == *"ERROR"* ]]; then
        log_validation "FAIL" "Swift Client Compatibility" "Request failed"
    else
        # Check if response format matches expected Swift client requirements
        local message_content=$(echo "$response" | jq -r '.choices[0].message.content // "missing"')
        local finish_reason=$(echo "$response" | jq -r '.choices[0].finish_reason // "missing"')
        
        if [[ "$message_content" != "missing" && "$finish_reason" != "missing" ]]; then
            log_validation "PASS" "Swift Client Compatibility" "Response format compatible with Swift client"
        else
            log_validation "FAIL" "Swift Client Compatibility" "Response format not compatible (missing content or finish_reason)"
        fi
    fi
    
    # Test Go API Gateway compatibility
    local go_client_test='{"model": "lfm2:1.2b", "messages": [{"role": "user", "content": "Go integration test"}]}'
    
    local go_response=$(curl -s -X POST "http://localhost:$GO_API_PORT/api/llm/chat" \
        -H "Content-Type: application/json" \
        -H "X-Service-Target: mlx" \
        -d "$go_client_test" \
        --max-time 30 || echo "ERROR")
    
    if [[ "$go_response" == *"ERROR"* ]]; then
        log_validation "WARN" "Go Gateway Integration" "Direct integration not yet configured - expected for initial migration"
    else
        log_validation "PASS" "Go Gateway Integration" "MLX service accessible through Go gateway"
    fi
}

# Validate error handling consistency
validate_error_handling() {
    echo -e "\n${BLUE}‚ö†Ô∏è  Validating Error Handling${NC}"
    echo "============================="
    
    # Test various error scenarios
    local error_tests=(
        '{"invalid": "request"}|Invalid Request Format'
        '{"model": "nonexistent", "messages": [{"role": "user", "content": "test"}]}|Invalid Model'
        '{"model": "lfm2:1.2b", "messages": []}|Empty Messages'
        '{"model": "lfm2:1.2b", "messages": [{"role": "invalid", "content": "test"}]}|Invalid Role'
    )
    
    for test_case in "${error_tests[@]}"; do
        IFS='|' read -r request error_type <<< "$test_case"
        
        local error_response=$(curl -s -X POST "http://localhost:$MLX_SERVICE_PORT/api/chat/completions" \
            -H "Content-Type: application/json" \
            -d "$request" \
            --max-time 10 || echo "TIMEOUT")
        
        local http_code=$(curl -s -o /dev/null -w "%{http_code}" -X POST "http://localhost:$MLX_SERVICE_PORT/api/chat/completions" \
            -H "Content-Type: application/json" \
            -d "$request" \
            --max-time 10 || echo "000")
        
        # Check if error is handled gracefully
        if [[ "$http_code" =~ ^[45][0-9][0-9]$ ]]; then
            # Check if error response has proper structure
            local has_error=$(echo "$error_response" | jq -r '.error // "missing"')
            if [[ "$has_error" != "missing" ]]; then
                log_validation "PASS" "Error Handling" "$error_type returns HTTP $http_code with proper error structure"
            else
                log_validation "WARN" "Error Handling" "$error_type returns HTTP $http_code but missing error structure"
            fi
        elif [[ "$http_code" == "200" ]]; then
            log_validation "WARN" "Error Handling" "$error_type should return error but got HTTP 200"
        else
            log_validation "FAIL" "Error Handling" "$error_type handling failed (HTTP $http_code)"
        fi
    done
}

# Test streaming compatibility (if supported)
validate_streaming_compatibility() {
    echo -e "\n${BLUE}üì° Validating Streaming Compatibility${NC}"
    echo "===================================="
    
    # Test streaming request
    local streaming_request='{"model": "lfm2:1.2b", "messages": [{"role": "user", "content": "Count to 5"}], "stream": true}'
    
    # Capture streaming response
    local stream_output="$VALIDATION_DIR/stream_test_$TIMESTAMP.txt"
    
    timeout 15s curl -s -X POST "http://localhost:$MLX_SERVICE_PORT/api/chat/completions" \
        -H "Content-Type: application/json" \
        -H "Accept: text/event-stream" \
        -d "$streaming_request" > "$stream_output" 2>&1 || true
    
    if [[ -s "$stream_output" ]]; then
        local line_count=$(wc -l < "$stream_output")
        if [[ $line_count -gt 1 ]]; then
            log_validation "PASS" "Streaming Support" "Received $line_count lines of streaming data"
        else
            log_validation "WARN" "Streaming Support" "Streaming not properly implemented or single response"
        fi
    else
        log_validation "WARN" "Streaming Support" "Streaming not supported or failed to connect"
    fi
}

# Validate monitoring and metrics compatibility
validate_monitoring_compatibility() {
    echo -e "\n${BLUE}üìä Validating Monitoring Compatibility${NC}"
    echo "======================================"
    
    # Test metrics endpoint
    local metrics_response=$(curl -s "http://localhost:$MLX_SERVICE_PORT/metrics" || echo "ERROR")
    
    if [[ "$metrics_response" == *"ERROR"* ]]; then
        log_validation "FAIL" "Metrics Endpoint" "Metrics endpoint not accessible"
    else
        # Check for expected metric types
        local has_response_time=$(echo "$metrics_response" | grep -c "response_time\|duration" || true)
        local has_request_count=$(echo "$metrics_response" | grep -c "request_count\|requests_total" || true)
        local has_error_rate=$(echo "$metrics_response" | grep -c "error_rate\|errors_total" || true)
        
        if [[ $has_response_time -gt 0 && $has_request_count -gt 0 ]]; then
            log_validation "PASS" "Metrics Content" "Found response time and request count metrics"
        else
            log_validation "WARN" "Metrics Content" "Missing expected metrics (response_time: $has_response_time, requests: $has_request_count)"
        fi
    fi
    
    # Test health endpoint detailed response
    local health_response=$(curl -s "http://localhost:$MLX_SERVICE_PORT/health" || echo "ERROR")
    
    if [[ "$health_response" == *"ERROR"* ]]; then
        log_validation "FAIL" "Health Endpoint" "Health endpoint not accessible"
    else
        local has_status=$(echo "$health_response" | jq -r '.status // "missing"')
        local has_timestamp=$(echo "$health_response" | jq -r '.timestamp // "missing"')
        
        if [[ "$has_status" != "missing" && "$has_timestamp" != "missing" ]]; then
            log_validation "PASS" "Health Response" "Health endpoint returns proper structure"
        else
            log_validation "WARN" "Health Response" "Health endpoint missing expected fields"
        fi
    fi
}

# Test performance under load to ensure no regression
validate_performance_regression() {
    echo -e "\n${BLUE}‚ö° Validating Performance Regression${NC}"
    echo "===================================="
    
    # Quick performance test
    local test_start=$(date +%s%N)
    local quick_response=$(curl -s -X POST "http://localhost:$MLX_SERVICE_PORT/api/chat/completions" \
        -H "Content-Type: application/json" \
        -d '{"model": "lfm2:1.2b", "messages": [{"role": "user", "content": "Quick test"}], "max_tokens": 10}' \
        --max-time 20 || echo "ERROR")
    local test_end=$(date +%s%N)
    
    if [[ "$quick_response" == *"ERROR"* ]]; then
        log_validation "FAIL" "Performance Test" "Quick performance test failed"
    else
        local response_time=$((($test_end - $test_start) / 1000000))
        
        # Compare against baseline (if available)
        if [[ $response_time -lt 2000 ]]; then
            log_validation "PASS" "Performance Test" "Response time ${response_time}ms is acceptable"
        elif [[ $response_time -lt 5000 ]]; then
            log_validation "WARN" "Performance Test" "Response time ${response_time}ms is slow but acceptable"
        else
            log_validation "FAIL" "Performance Test" "Response time ${response_time}ms exceeds acceptable threshold"
        fi
    fi
}

# Generate compatibility report
generate_compatibility_report() {
    echo -e "\n${BLUE}üìã Generating Compatibility Report${NC}"
    echo "=================================="
    
    local report_file="$VALIDATION_DIR/compatibility_report_$TIMESTAMP.json"
    
    cat > "$report_file" << EOF
{
  "validation_metadata": {
    "timestamp": "$(date -Iseconds)",
    "service": "mlx-lfm2-migration",
    "migration_type": "lfm2_typescript_to_mlx_rust"
  },
  "validation_summary": {
    "total_validations": $TOTAL_VALIDATIONS,
    "passed_validations": $PASSED_VALIDATIONS,
    "failed_validations": $FAILED_VALIDATIONS,
    "success_rate": "$(echo "scale=1; ($PASSED_VALIDATIONS / $TOTAL_VALIDATIONS) * 100" | bc -l)%"
  },
  "compatibility_status": {
    "api_endpoints": "$(get_endpoint_status)",
    "request_response_schema": "$(get_schema_status)",
    "client_compatibility": "$(get_client_status)",
    "error_handling": "$(get_error_status)",
    "monitoring": "$(get_monitoring_status)"
  },
  "migration_readiness": {
    "ready_for_production": $(get_production_readiness),
    "breaking_changes_detected": $(get_breaking_changes),
    "recommended_actions": [
      "$(generate_compatibility_recommendations)"
    ]
  }
}
EOF
    
    log_validation "INFO" "Compatibility Report" "Generated report: $report_file"
    
    # Display summary
    echo -e "\n${GREEN}üéØ Compatibility Validation Summary${NC}"
    echo "========================================"
    echo -e "  Total Validations: $TOTAL_VALIDATIONS"
    echo -e "  Passed: ${GREEN}$PASSED_VALIDATIONS${NC}"
    echo -e "  Failed: ${RED}$FAILED_VALIDATIONS${NC}"
    echo -e "  Success Rate: $(echo "scale=1; ($PASSED_VALIDATIONS / $TOTAL_VALIDATIONS) * 100" | bc -l)%"
}

# Helper functions for report generation
get_endpoint_status() {
    if [[ $FAILED_VALIDATIONS -eq 0 ]]; then
        echo "Compatible"
    elif [[ $PASSED_VALIDATIONS -gt $FAILED_VALIDATIONS ]]; then
        echo "Mostly Compatible"
    else
        echo "Incompatible"
    fi
}

get_schema_status() {
    echo "Compatible" # Would be determined by schema validation results
}

get_client_status() {
    echo "Compatible" # Would be determined by client compatibility tests
}

get_error_status() {
    echo "Compatible" # Would be determined by error handling tests
}

get_monitoring_status() {
    echo "Compatible" # Would be determined by monitoring tests
}

get_production_readiness() {
    if [[ $FAILED_VALIDATIONS -eq 0 ]]; then
        echo "true"
    else
        echo "false"
    fi
}

get_breaking_changes() {
    if [[ $FAILED_VALIDATIONS -gt 0 ]]; then
        echo "true"
    else
        echo "false"
    fi
}

generate_compatibility_recommendations() {
    if [[ $FAILED_VALIDATIONS -eq 0 ]]; then
        echo "No breaking changes detected. Migration is ready for production."
    else
        echo "Address $FAILED_VALIDATIONS failed validations before production deployment."
    fi
}

# Main execution
main() {
    validate_endpoint_structure
    validate_chat_completions_schema
    validate_client_compatibility
    validate_error_handling
    validate_streaming_compatibility
    validate_monitoring_compatibility
    validate_performance_regression
    generate_compatibility_report
    
    echo -e "\n${GREEN}üèÅ API Compatibility Validation Complete${NC}"
    echo "=========================================="
    echo -e "Results directory: ${BLUE}$VALIDATION_DIR${NC}"
    echo -e "Validation log: ${BLUE}$VALIDATION_LOG${NC}"
    echo -e "Compatibility report: ${BLUE}$VALIDATION_DIR/compatibility_report_$TIMESTAMP.json${NC}"
    
    if [[ $FAILED_VALIDATIONS -eq 0 ]]; then
        echo -e "\n${GREEN}‚úÖ All compatibility validations passed! Migration is safe to proceed.${NC}"
        exit 0
    else
        echo -e "\n${RED}‚ö†Ô∏è  $FAILED_VALIDATIONS compatibility issues detected. Review required before production.${NC}"
        exit 1
    fi
}

# Execute main function
main "$@"